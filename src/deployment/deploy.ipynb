{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one.\n",
        "\n",
        "![image of workspace credentials](./media/find-credentials.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748815240337
        },
        "name": "ml_client"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION = \"<YOUR_SUBSCRIPTION_ID>\"\n",
        "RESOURCE_GROUP = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
        "WS_NAME = \"<YOUR_WORKSPACE_NAME>\"\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748815274701
        }
      },
      "outputs": [],
      "source": [
        "# Verify that the handle works correctly.\n",
        "# If you ge an error here, modify your SUBSCRIPTION, RESOURCE_GROUP, and WS_NAME in the previous cell.\n",
        "ws = ml_client.workspaces.get(WS_NAME)\n",
        "print(ws.location, \":\", ws.resource_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1748829718924
        },
        "name": "train_src_dir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a model and return the output model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "name": "write_main"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import argparse\n",
        "import lightgbm as lgb\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    ###################\n",
        "    #<prepare the data>\n",
        "    ###################\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "    print(\"input data:\", args.data)\n",
        "\n",
        "    df = pl.read_excel(source=\"./data/full_join.xlsx\", sheet_name=\"Sheet1\")\n",
        "    df = df.with_columns([\n",
        "        pl.col(\"CostImpact (â‚¬)\").cast(pl.Float64, strict=False),\n",
        "    ])\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\",df.shape[1] - 1)\n",
        "\n",
        "    df_input = (\n",
        "        df\n",
        "        .filter(pl.col(\"PackagingQuality\").is_in([\"Bad\", \"Good\"])) \n",
        "        .sort(\"DateOfReport\")                                      \n",
        "        .select([                                                 \n",
        "            \"SupplierName\",\n",
        "            \"GarmentType\",\n",
        "            \"Material\",\n",
        "            \"Weight\",\n",
        "            \"ProposedUnitsPerCarton\",\n",
        "            \"ProposedFoldingMethod\",\n",
        "            \"ProposedLayout\",\n",
        "            \"Size\",\n",
        "            \"Collection\",\n",
        "            \"PackagingQuality\"\n",
        "        ])\n",
        "    )\n",
        "    # Convert Polars to Pandas\n",
        "    df_pd = df_input.to_pandas()\n",
        "\n",
        "    # Encode target variable\n",
        "    df_pd[\"PackagingQuality\"] = df_pd[\"PackagingQuality\"].map({\"Good\": 1, \"Bad\": 0})\n",
        "\n",
        "    # Define features and target\n",
        "    X = df_pd.drop(columns=[\"PackagingQuality\"])\n",
        "    y = df_pd[\"PackagingQuality\"]\n",
        "    categorical_features = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.30, random_state=42, stratify=y\n",
        "    )\n",
        "    ####################\n",
        "    #</prepare the data>\n",
        "    ####################\n",
        "\n",
        "    ##################\n",
        "    #<train the model>\n",
        "    ##################\n",
        "    #weights\n",
        "    class_weights = np.where(y_train == 1, 1, 4)  \n",
        "\n",
        "    # Instantiate the LightGBM classifier\n",
        "    model_lgb = lgb.LGBMClassifier(\n",
        "        objective='binary',\n",
        "        metric='auc',\n",
        "        boosting_type='gbdt',\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    for c in categorical_features:\n",
        "        X_train[c] = X_train[c].astype(\"category\")\n",
        "        X_test[c] = X_test[c].astype(\"category\")\n",
        "\n",
        "    actual_categorical_in_train = [col for col in categorical_features if col in X_train.columns and X_train[col].dtype.name == 'category']\n",
        "\n",
        "    # Train the model\n",
        "    model_lgb.fit(X_train, y_train, sample_weight=class_weights,categorical_feature=actual_categorical_in_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_lgb = model_lgb.predict(X_test)\n",
        "    y_proba_lgb = model_lgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(classification_report(y_test, y_pred_lgb))\n",
        "    ###################\n",
        "    #</train the model>\n",
        "    ###################\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=model_lgb,\n",
        "        registered_model_name=\"packaging_quality_default_model\",\n",
        "        artifact_path=\"packaging_quality_default_model\",\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=model_lgb,\n",
        "        path=os.path.join(\"packaging_quality_default_model\", \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748829768579
        },
        "name": "registered_model_name"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "registered_model_name = \"packaging_quality_default_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"capstone-v2@latest\",\n",
        "    display_name=\"packaging_quality_default_prediction\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748829776274
        },
        "name": "create_job"
      },
      "outputs": [],
      "source": [
        "ml_client.create_or_update(job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a new online endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748832169934
        },
        "name": "online_endpoint_name"
      },
      "outputs": [],
      "source": [
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"pckg-quality-endpoint\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748832279531
        },
        "name": "endpoint"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint pckg-quality-endpoint provisioning state: Succeeded\n"
          ]
        }
      ],
      "source": [
        "# Expect the endpoint creation to take a few minutes\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"sample online endpoint for ML model deployment\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"packaging_quality_full_join\",\n",
        "        \"model_type\": \"lightgbm.LGBMClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1748832279895
        },
        "name": "retrieve_endpoint"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint \"pckg-quality-endpoint\" with provisioning state \"Succeeded\" is retrieved\n"
          ]
        }
      ],
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the model to the endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1748838213702
        }
      },
      "outputs": [],
      "source": [
        "registered_model_name = \"packaging_quality_default_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1748838214366
        },
        "name": "latest_model_version"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest model is version \"1\" \n"
          ]
        }
      ],
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")\n",
        "print(f'Latest model is version \"{latest_model_version}\" ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deploy the latest version of the model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1748838216582
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration, Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1748838217903
        }
      },
      "outputs": [],
      "source": [
        "env = ml_client.environments.get(name=\"packaging_quality_default_model\", version=\"4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1748840254895
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint pckg-quality-endpoint exists\n",
            "Uploading src (53.57 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53572876/53572876 [00:00<00:00, 88021084.27it/s]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".............................................................."
          ]
        }
      ],
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "blue = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\",\n",
        "        scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=env,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.begin_create_or_update(blue).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1748824295583
        },
        "name": "blue_deployment"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint pckg-quality-endpoint-v4 exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".................................................................................."
          ]
        }
      ],
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "# Expect this deployment to take approximately 6 to 8 minutes.\n",
        "# create an online deployment.\n",
        "# if you run into an out of quota error, change the instance_type to a comparable VM that is available.\n",
        "# Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "green_deployment = ManagedOnlineDeployment(\n",
        "    name=\"green\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.begin_create_or_update(green_deployment).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test with a sample query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679004374166
        },
        "name": "deploy_dir"
      },
      "outputs": [],
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "write_sample"
      },
      "outputs": [],
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"index\": [0, 1],\n",
        "    \"columns\": [\n",
        "      \"SupplierName\",\n",
        "      \"GarmentType\",\n",
        "      \"Material\",\n",
        "      \"Weight\",\n",
        "      \"ProposedUnitsPerCarton\",\n",
        "      \"ProposedFoldingMethod\",\n",
        "      \"ProposedLayout\",\n",
        "      \"Size\",\n",
        "      \"Collection\"\n",
        "    ],\n",
        "    \"data\": [\n",
        "      [\"SupplierC\", \"Shorts\", \"Polyester\", 0.22, 31, \"Method1\", \"LayoutA\", \"XS\", \"Spring\"],\n",
        "      [\"SupplierH\", \"Shirt\", \"Polyester\", 0.16, 45, \"Method2\", \"LayoutA\", \"L\", \"Summer\"],\n",
        "      [\"SupplierC\", \"Skirt\", \"Cotton\", 0.30, 30, \"Method2\", \"LayoutC\", \"M\", \"Summer\"],\n",
        "      [\"SupplierA\", \"Coat\", \"Cotton\", 1.29, 6, \"Method1\", \"LayoutD\", \"M\", \"Spring\"],\n",
        "      [\"SupplierA\", \"Jacket\", \"Cotton\", 0.91, 14, \"Method1\", \"LayoutC\", \"L\", \"Spring\"]\n",
        "    ]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "test"
      },
      "outputs": [],
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials",
      "get-started-notebooks"
    ],
    "description": "Learn how a data scientist uses Azure Machine Learning to train a model, then use the model for prediction. This tutorial will help you become familiar with the core concepts of Azure ML and their most common usage.",
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
