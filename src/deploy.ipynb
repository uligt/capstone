{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# First look at Azure Machine Learning\n",
        "\n",
        "This tutorial is an introduction to some of the most used features of the Azure Machine Learning service.  In it, you will create, register and deploy a model. This tutorial will help you become familiar with the core concepts of Azure Machine Learning and their most common usage. \n",
        "\n",
        "You'll learn how to run a training job on a scalable compute resource, then deploy it, and finally test the deployment.\n",
        "\n",
        "You'll create a training script to handle the data preparation, train and register a model. Once you train the model, you'll *deploy* it as an *endpoint*, then call the endpoint for *inferencing*.\n",
        "\n",
        "The steps you'll take are:\n",
        "\n",
        "> * Set up a handle to your Azure Machine Learning workspace\n",
        "> * Create your training script\n",
        "> * Create and run a command job that will run the training script on the compute cluster, configured with the appropriate job environment\n",
        "> * View the output of your training script\n",
        "> * Deploy the newly-trained model as an endpoint\n",
        "> * Call the Azure Machine Learning endpoint for inferencing\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "* If you opened this notebook from Azure Machine Learning studio, you need a compute instance to run the code. If you don't have a compute instance, select **Create compute** on the toolbar to first create one.  You can use all the default settings.  \n",
        "\n",
        "    ![Create compute](./media/create-compute.png)\n",
        "\n",
        "* If you're seeing this notebook elsewhere, complete [Create resources you need to get started](https://docs.microsoft.com/azure/machine-learning/quickstart-create-resources) to create an Azure Machine Learning workspace and a compute instance.\n",
        "\n",
        "## Set your kernel\n",
        "\n",
        "* If your compute instance is stopped, start it now.  \n",
        "        \n",
        "    ![Start compute](./media/start-compute.png)\n",
        "\n",
        "* Once your compute instance is running, make sure the that the kernel, found on the top right, is `Python 3.10 - SDK v2`.  If not, use the dropdown to select this kernel.\n",
        "\n",
        "    ![Set the kernel](./media/set-kernel.png)"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create handle to workspace\n",
        "\n",
        "Before we dive in the code, you need a way to reference your workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "You'll create `ml_client` for a handle to the workspace.  You'll then use `ml_client` to manage resources and jobs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one.\n",
        "\n",
        "![image of workspace credentials](./media/find-credentials.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION = \"16f8602a-0338-40fc-8d56-5ea6a5210daa\"\n",
        "RESOURCE_GROUP = \"IE\"\n",
        "WS_NAME = \"Capstone\"\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1748815240337
        },
        "name": "ml_client"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "> [!NOTE]\n",
        "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that the handle works correctly.\n",
        "# If you ge an error here, modify your SUBSCRIPTION, RESOURCE_GROUP, and WS_NAME in the previous cell.\n",
        "ws = ml_client.workspaces.get(WS_NAME)\n",
        "print(ws.location, \":\", ws.resource_group)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "eastus : IE\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1748815274701
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training script\n",
        "\n",
        "Let's start by creating the training script - the *main.py* Python file.\n",
        "\n",
        "First create a source folder for the script:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1748829718924
        },
        "name": "train_src_dir"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. \n",
        "\n",
        "[MLFlow](https://learn.microsoft.com/azure/machine-learning/how-to-log-mlflow-models) will be used to log the parameters and metrics during our pipeline run. \n",
        "\n",
        "The cell below uses IPython magic to write the training script into the directory you just created."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import argparse\n",
        "import lightgbm as lgb\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    ###################\n",
        "    #<prepare the data>\n",
        "    ###################\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "    print(\"input data:\", args.data)\n",
        "\n",
        "    df = pl.read_excel(source=\"./data/full_join.xlsx\", sheet_name=\"Sheet1\")\n",
        "    df = df.with_columns([\n",
        "        pl.col(\"CostImpact (â‚¬)\").cast(pl.Float64, strict=False),\n",
        "    ])\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\",df.shape[1] - 1)\n",
        "\n",
        "    df_input = (\n",
        "        df\n",
        "        .filter(pl.col(\"PackagingQuality\").is_in([\"Bad\", \"Good\"])) \n",
        "        .sort(\"DateOfReport\")                                      \n",
        "        .select([                                                 \n",
        "            \"SupplierName\",\n",
        "            \"GarmentType\",\n",
        "            \"Material\",\n",
        "            \"Weight\",\n",
        "            \"ProposedUnitsPerCarton\",\n",
        "            \"ProposedFoldingMethod\",\n",
        "            \"ProposedLayout\",\n",
        "            \"Size\",\n",
        "            \"Collection\",\n",
        "            \"PackagingQuality\"\n",
        "        ])\n",
        "    )\n",
        "    # Convert Polars to Pandas\n",
        "    df_pd = df_input.to_pandas()\n",
        "\n",
        "    # Encode target variable\n",
        "    df_pd[\"PackagingQuality\"] = df_pd[\"PackagingQuality\"].map({\"Good\": 1, \"Bad\": 0})\n",
        "\n",
        "    # Define features and target\n",
        "    X = df_pd.drop(columns=[\"PackagingQuality\"])\n",
        "    y = df_pd[\"PackagingQuality\"]\n",
        "    categorical_features = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.30, random_state=42, stratify=y\n",
        "    )\n",
        "    ####################\n",
        "    #</prepare the data>\n",
        "    ####################\n",
        "\n",
        "    ##################\n",
        "    #<train the model>\n",
        "    ##################\n",
        "    #weights\n",
        "    class_weights = np.where(y_train == 1, 1, 4)  \n",
        "\n",
        "    # Instantiate the LightGBM classifier\n",
        "    model_lgb = lgb.LGBMClassifier(\n",
        "        objective='binary',\n",
        "        metric='auc',\n",
        "        boosting_type='gbdt',\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    for c in categorical_features:\n",
        "        X_train[c] = X_train[c].astype(\"category\")\n",
        "        X_test[c] = X_test[c].astype(\"category\")\n",
        "\n",
        "    actual_categorical_in_train = [col for col in categorical_features if col in X_train.columns and X_train[col].dtype.name == 'category']\n",
        "\n",
        "    # Train the model\n",
        "    model_lgb.fit(X_train, y_train, sample_weight=class_weights,categorical_feature=actual_categorical_in_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_lgb = model_lgb.predict(X_test)\n",
        "    y_proba_lgb = model_lgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(classification_report(y_test, y_pred_lgb))\n",
        "    ###################\n",
        "    #</train the model>\n",
        "    ###################\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=model_lgb,\n",
        "        registered_model_name=\"packaging_quality_default_model\",\n",
        "        artifact_path=\"packaging_quality_default_model\",\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=model_lgb,\n",
        "        path=os.path.join(\"packaging_quality_default_model\", \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/main.py\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "name": "write_main"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "As you can see in this script, once the model is trained, the model file is saved and registered to the workspace. Now you can use the registered model in inferencing endpoints.\n",
        "\n",
        "You might need to select **Refresh** to see the new folder and script in your **Files**.\n",
        "\n",
        "![refresh](./media/refresh.png)"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Configure the command\n",
        "\n",
        "Now that you have a script that can perform the desired tasks, and a compute cluster to run the script, you'll use a general purpose **command** that can run command line actions. This command line action can directly call system commands or run a script. \n",
        "\n",
        "Here, you'll create input variables to specify the input data, split ratio, learning rate and registered model name.  The command script will:\n",
        "* Use an *environment* that defines software and runtime libraries needed for the training script. Azure Machine Learning provides many curated or ready-made environments, which are useful for common training and inference scenarios. You'll use one of those environments here.  In the [Train a model](train-model.ipynb) tutorial, you'll learn how to create a custom environment. \n",
        "* Configure the command line action itself - `python main.py` in this case. The inputs/outputs are accessible in the command via the `${{ ... }}` notation.\n",
        "* In this sample, we access the data from a file on the internet. \n",
        "* Since a compute resource was not specified, the script will be run on a [serverless compute cluster](https://learn.microsoft.com/azure/machine-learning/how-to-use-serverless-compute?view=azureml-api-2&tabs=python) that is automatically created.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "registered_model_name = \"packaging_quality_default_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv\",\n",
        "        ),\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"capstone-v2@latest\",\n",
        "    display_name=\"packaging_quality_default_prediction\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1748829768579
        },
        "name": "registered_model_name"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.environments.delete(name=\"packaging_quality_default_model\", version=\"bf9ddc59a05d6c743fb3f171ea0cac630d2d15bb6ffd85c52af4e6a066a4cb76\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'EnvironmentOperations' object has no attribute 'delete'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackaging_quality_default_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf9ddc59a05d6c743fb3f171ea0cac630d2d15bb6ffd85c52af4e6a066a4cb76\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EnvironmentOperations' object has no attribute 'delete'"
          ]
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1748830782377
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit the job \n",
        "\n",
        "It's now time to submit the job to run in Azure Machine Learning. This time you'll use `create_or_update`  on `ml_client`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'funny_collar_h559vvpzg9', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': None, 'ContentSnapshotId': '60aa5de2-650a-47e9-8e86-f3af487455fe'}, 'print_as_yaml': False, 'id': '/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourceGroups/IE/providers/Microsoft.MachineLearningServices/workspaces/Capstone/jobs/funny_collar_h559vvpzg9', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/capstone-model-training/code/Users/castro.bafc/get-started-notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x714ae527b670>, 'serialize': <msrest.serialization.Serializer object at 0x714ae4313f40>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'packaging_quality_default_prediction', 'experiment_name': 'get-started-notebooks', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourceGroups/IE/providers/Microsoft.MachineLearningServices/workspaces/Capstone?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/funny_collar_h559vvpzg9?wsid=/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourcegroups/IE/workspaces/Capstone&tid=8f6217f7-aae3-40da-8108-c9066904d8c7', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv', 'mode': 'ro_mount'}, 'test_train_ratio': '0.2', 'learning_rate': '0.25', 'registered_model_name': 'packaging_quality_default_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.funny_collar_h559vvpzg9', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x714ae4313be0>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x714ae4313b80>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x714ae4313880>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x714ae4313790>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x714ae4313970>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'funny_collar_h559vvpzg9', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/capstone-model-training/code/Users/castro.bafc/get-started-notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x714ae527b670>, 'serialize': <msrest.serialization.Serializer object at 0x714ae4313fa0>, 'command': 'python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourceGroups/IE/providers/Microsoft.MachineLearningServices/workspaces/Capstone/codes/fdac479c-d788-4b26-a473-906db8be8ebc/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourceGroups/IE/providers/Microsoft.MachineLearningServices/workspaces/Capstone/environments/capstone-v2/versions/3', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'packaging_quality_default_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.2'}, 'learning_rate': {'type': 'string', 'default': '0.25'}, 'registered_model_name': {'type': 'string', 'default': 'packaging_quality_default_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.funny_collar_h559vvpzg9', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourceGroups/IE/providers/Microsoft.MachineLearningServices/workspaces/Capstone?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/funny_collar_h559vvpzg9?wsid=/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourcegroups/IE/workspaces/Capstone&tid=8f6217f7-aae3-40da-8108-c9066904d8c7', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x714ae527b670>}, 'instance_id': 'd80d9baa-3f07-4f28-aff2-d20d31d1d998', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'capstone-v2:3', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': {'job_tier': 'null'}, 'parent_job_name': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>get-started-notebooks</td><td>funny_collar_h559vvpzg9</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/funny_collar_h559vvpzg9?wsid=/subscriptions/16f8602a-0338-40fc-8d56-5ea6a5210daa/resourcegroups/IE/workspaces/Capstone&amp;tid=8f6217f7-aae3-40da-8108-c9066904d8c7\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1748829776274
        },
        "name": "create_job"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View job output and wait for job completion\n",
        "\n",
        "View the job in Azure Machine Learning studio by selecting the link in the output of the previous cell. \n",
        "\n",
        "The output of this job will look like this in the Azure Machine Learning studio. Explore the tabs for various details like metrics, outputs etc. Once completed, the job will register a model in your workspace as a result of training. \n",
        "\n",
        "![Screenshot that shows the job overview](./media/view-job.gif \"View the job in studio\")\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Wait until the status of the job is complete before returning to this notebook to continue. The job will take 2 to 3 minutes to run. It could take longer (up to 10 minutes) if the compute cluster has been scaled down to zero nodes and custom environment is still building."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model as an online endpoint\n",
        "\n",
        "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
        "\n",
        "To deploy a machine learning service, you'll use the model you registered."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a new online endpoint\n",
        "\n",
        "Now that you have a registered model, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"pckg-quality-endpoint\""
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1748832169934
        },
        "name": "online_endpoint_name"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "online_endpoint_name"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "'pckg-quality-endpoint'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1748832170240
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the endpoint:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Expect the endpoint creation to take a few minutes\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"packaging_quality_full_join\",\n",
        "        \"model_type\": \"lightgbm.LGBMClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint pckg-quality-endpoint provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1748832279531
        },
        "name": "endpoint"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [!NOTE]\n",
        "> Expect the endpoint creation to take a few minutes.\n",
        "\n",
        "Once the endpoint has been created, you can retrieve it as below:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint \"pckg-quality-endpoint\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1748832279895
        },
        "name": "retrieve_endpoint"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to the endpoint\n",
        "\n",
        "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments. Direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary.\n",
        "\n",
        "You can check the **Models** page on Azure Machine Learning studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_name = \"packaging_quality_default_model\""
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1748838213702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")\n",
        "print(f'Latest model is version \"{latest_model_version}\" ')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest model is version \"1\" \n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1748838214366
        },
        "name": "latest_model_version"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy the latest version of the model.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration, Environment"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1748838216582
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = ml_client.environments.get(name=\"packaging_quality_default_model\", version=\"4\")"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1748838217903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "# Expect this deployment to take approximately 6 to 8 minutes.\n",
        "# create an online deployment.\n",
        "# if you run into an out of quota error, change the instance_type to a comparable VM that is available.\n",
        "# Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "blue = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\",\n",
        "        scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=env,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.begin_create_or_update(blue).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint pckg-quality-endpoint exists\nUploading src (53.57 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53572876/53572876 [00:00<00:00, 88021084.27it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".............................................................."
        }
      ],
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1748840254895
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "# Expect this deployment to take approximately 6 to 8 minutes.\n",
        "# create an online deployment.\n",
        "# if you run into an out of quota error, change the instance_type to a comparable VM that is available.\n",
        "# Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "green_deployment = ManagedOnlineDeployment(\n",
        "    name=\"green\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.begin_create_or_update(green_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint pckg-quality-endpoint-v4 exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".................................................................................."
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1748824295583
        },
        "name": "blue_deployment"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [!NOTE]\n",
        "> Expect this deployment to take approximately 6 to 8 minutes.\n",
        "\n",
        "When the deployment is done, you're ready to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with a sample query\n",
        "\n",
        "Once the model is deployed to the endpoint, you can run inference with it.\n",
        "\n",
        "Create a sample request file following the design expected in the run method in the score script."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679004374166
        },
        "name": "deploy_dir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"index\": [0, 1],\n",
        "    \"columns\": [\n",
        "      \"SupplierName\",\n",
        "      \"GarmentType\",\n",
        "      \"Material\",\n",
        "      \"Weight\",\n",
        "      \"ProposedUnitsPerCarton\",\n",
        "      \"ProposedFoldingMethod\",\n",
        "      \"ProposedLayout\",\n",
        "      \"Size\",\n",
        "      \"Collection\"\n",
        "    ],\n",
        "    \"data\": [\n",
        "      [\"SupplierC\", \"Shorts\", \"Polyester\", 0.22, 31, \"Method1\", \"LayoutA\", \"XS\", \"Spring\"],\n",
        "      [\"SupplierH\", \"Shirt\", \"Polyester\", 0.16, 45, \"Method2\", \"LayoutA\", \"L\", \"Summer\"],\n",
        "      [\"SupplierC\", \"Skirt\", \"Cotton\", 0.30, 30, \"Method2\", \"LayoutC\", \"M\", \"Summer\"],\n",
        "      [\"SupplierA\", \"Coat\", \"Cotton\", 1.29, 6, \"Method1\", \"LayoutD\", \"M\", \"Spring\"],\n",
        "      [\"SupplierA\", \"Jacket\", \"Cotton\", 0.91, 14, \"Method1\", \"LayoutC\", \"L\", \"Spring\"]\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "name": "write_sample"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "name": "test"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
        "\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect the complete deletion to take approximately 20 minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "name": "delete_endpoint"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "You now have an Azure Machine Learning workspace, which contains a compute instance to use for your development environment.\n",
        "\n",
        "Continue on to learn how to use the compute instance to run notebooks and scripts in the Azure Machine Learning cloud. \n",
        "\n",
        "|Tutorial  |Description  |\n",
        "|---------|---------|\n",
        "| [Tutorial: Upload, access and explore your data in Azure Machine Learning](https://learn.microsoft.com/azure/tutorial-explore-data)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\n",
        "| [Tutorial: Model development on a cloud workstation](https://learn.microsoft.com/azure/tutorial-cloud-workstation) | Start prototyping and developing machine learning models |\n",
        "| [Tutorial: Train a model in Azure Machine Learning](https://learn.microsoft.com/azure/tutorial-train-model) |    Dive in to the details of training a model     |\n",
        "| [Tutorial: Deploy a model as an online endpoint](https://learn.microsoft.com/azure/tutorial-deploy-model)  |   Dive in to the details of deploying a model      |\n",
        "| [Tutorial: Create production machine learning pipelines](https://learn.microsoft.com/azure/tutorial-pipeline-python-sdk) | Split a complete machine learning task into a multistep workflow. |\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "description": "Learn how a data scientist uses Azure Machine Learning to train a model, then use the model for prediction. This tutorial will help you become familiar with the core concepts of Azure ML and their most common usage.",
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "categories": [
      "SDK v2",
      "tutorials",
      "get-started-notebooks"
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 2
}