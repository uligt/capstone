{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_9nryk7DPtX"
   },
   "source": [
    "# Data cleaning & Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBARle-BiX4b"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11748,
     "status": "ok",
     "timestamp": 1748834400378,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "UDa2w5NgiZKW",
    "outputId": "5b43cbd8-94ba-45ce-f537-8d5ab7ab9d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastexcel in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install fastexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1748834405914,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "bPoCO-5gqsqE",
    "outputId": "2095a4ca-2a5e-4051-af87-354d94b14746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.11/dist-packages (3.2.3)\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1748834406881,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "Z_JWQ-EZFOd0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l751Y4pzFSGQ"
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748834406894,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "2r_OfAHoFWCq"
   },
   "outputs": [],
   "source": [
    "# Input paths\n",
    "PATH_DENSITY_REPORT       = 'DensityReports.xlsx'\n",
    "PATH_HISTORICAL_INCIDENTS = 'HistoricalIncidents.xlsx'\n",
    "PATH_PRODUCT_ATTRIBUTES   = 'ProductAttributes.xlsx'\n",
    "PATH_SUPPLIER_SCORECARD   = 'SupplierScorecard.xlsx'\n",
    "\n",
    "# Export paths\n",
    "EXPORT_DENSITY_REPORT       = 'density_report.xlsx'\n",
    "EXPORT_HISTORICAL_INCIDENTS = 'historical_incidents.xlsx'\n",
    "EXPORT_PRODUCT_ATTRIBUTES   = 'product_attributes.xlsx'\n",
    "EXPORT_SUPPLIER_SCORECARD   = 'supplier_scorecard.xlsx'\n",
    "EXPORT_FULL_JOIN            = 'full_join.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZpkTTkwilQu"
   },
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKxU3mwf_4BN"
   },
   "source": [
    "### 1. Read excel files with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1748834406898,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "zut0lQNJioXd"
   },
   "outputs": [],
   "source": [
    "def polars_read_excel(file_name, sheet_name='Sheet1'):\n",
    "  return pl.read_excel(source=file_name, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKHEnncl_-YM"
   },
   "source": [
    "### 2. Removing invalid strings in Product Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748834406905,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "trr2YqLyAbRk"
   },
   "outputs": [],
   "source": [
    "def clean_product_reference_column(df: pl.DataFrame, column_name: str, valid_pattern: str = r\"^PRD\\d{5}$\") -> pl.DataFrame:\n",
    "    # Ensure the column is cast to string\n",
    "    series_string = df[column_name].cast(pl.Utf8, strict=False)\n",
    "\n",
    "    # Remove trailing 'X' characters\n",
    "    cleaned_series = series_string.str.strip_chars_end('X')\n",
    "\n",
    "    # Check which values match the valid pattern\n",
    "    is_valid = cleaned_series.str.contains(valid_pattern)\n",
    "\n",
    "    # Replace invalid entries with None\n",
    "    corrected_series = pl.when(is_valid).then(cleaned_series).otherwise(None)\n",
    "\n",
    "    # Return the dataframe with the updated column\n",
    "    return df.with_columns([corrected_series.alias(column_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbmzxdzCUiR8"
   },
   "source": [
    "### 3. Modify column based on a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748834406906,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "HhAcOJM4Ug0s"
   },
   "outputs": [],
   "source": [
    "def clean_column_with_mapping(df: pl.DataFrame, col_name: str, mapping_dict: dict) -> pl.DataFrame:\n",
    "    cleaned_col = (\n",
    "        df[col_name]\n",
    "        .cast(pl.Utf8, strict=False)\n",
    "        .str.strip_chars()\n",
    "        .str.replace_all(\" \", \"\")\n",
    "        .map_elements(lambda val: mapping_dict.get(val, val), return_dtype=pl.Utf8)\n",
    "    )\n",
    "\n",
    "    return df.with_columns([cleaned_col.alias(col_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ_hUhl5x3pr"
   },
   "source": [
    "### 4. Most frequent combination of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1748834406909,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "5HMa-ZVqx3Eg"
   },
   "outputs": [],
   "source": [
    "def most_common_combination(df: pl.DataFrame, group_cols: list[str], additional_cols: list[str] = []) -> pl.DataFrame:\n",
    "  return (\n",
    "      df\n",
    "      .group_by(group_cols + additional_cols)\n",
    "      .agg(pl.len().alias(\"count\"))\n",
    "      .sort(group_cols + [\"count\"], descending=[False] * len(group_cols) + [True])\n",
    "      .unique(subset=group_cols, keep='first')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpo3gFfBar6l"
   },
   "source": [
    "### 5. Replace invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1748834406912,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "uVZ-rF7rasTE"
   },
   "outputs": [],
   "source": [
    "def replace_invalid_values(df: pl.DataFrame, target_col: str, invalid_values: list[str], group_cols: list[str]) -> pl.DataFrame:\n",
    "\n",
    "    # Get most common valid values per group\n",
    "    df_most_common = most_common_combination(\n",
    "        df.filter(~pl.col(target_col).is_in(invalid_values)),\n",
    "        group_cols,\n",
    "        additional_cols=[target_col]\n",
    "    )\n",
    "\n",
    "    # Build replacements for each invalid value\n",
    "    fixed_parts = []\n",
    "    for val in invalid_values:\n",
    "        df_invalid = df.filter(pl.col(target_col) == val)\n",
    "        df_replaced = (\n",
    "            df_invalid.drop(target_col)\n",
    "            .join(\n",
    "                df_most_common.select(group_cols + [target_col]),\n",
    "                on=group_cols,\n",
    "                how=\"left\"\n",
    "            )\n",
    "        )\n",
    "        fixed_parts.append(df_replaced)\n",
    "\n",
    "    # Retain all valid entries\n",
    "    df_cleaned = df.filter(~pl.col(target_col).is_in(invalid_values))\n",
    "\n",
    "    # Ensure consistent column order\n",
    "    column_order = df_cleaned.columns\n",
    "    fixed_parts = [part.select(column_order) for part in fixed_parts]\n",
    "\n",
    "    return pl.concat([df_cleaned] + fixed_parts, how=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQmXcW2oaEwG"
   },
   "source": [
    "### 6. Supplier Scorecard aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1748834406928,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "bKUKsTMdaEwH"
   },
   "outputs": [],
   "source": [
    "def aggregate_supplier_scorecard(df_scorecard: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Aggregate core metrics\n",
    "    df_agg = df_scorecard.group_by(['SupplierName', 'Month']).agg([\n",
    "        pl.sum('PackagesHandled').alias('PackagesHandled'),\n",
    "        pl.sum('TotalIncidents').alias('TotalIncidents'),\n",
    "        pl.sum('AnomaliesDetected').alias('AnomaliesDetected'),\n",
    "        (pl.col('PackagesHandled') * pl.col('BadPackagingRate (%)') / 100).sum().alias('TotalBadPackages'),\n",
    "        (pl.col('PackagesHandled') * pl.col('OnTimeDeliveryRate (%)') / 100).sum().alias('TotalOnTimePackages'),\n",
    "        (pl.col('AverageCostPerIncident (€)') * pl.col('TotalIncidents')).sum().alias('TotalIncidentCost')\n",
    "    ])\n",
    "\n",
    "    # Calculate final KPIs and round\n",
    "    ph = pl.col('PackagesHandled')\n",
    "    ti = pl.col('TotalIncidents')\n",
    "\n",
    "    df_final = df_agg.with_columns([\n",
    "        (pl.when(ph > 0).then(pl.col('TotalBadPackages') * 100 / ph).otherwise(0.0))\n",
    "        .round(2).alias('BadPackagingRate (%)'),\n",
    "\n",
    "        (pl.when(ph > 0).then(pl.col('TotalOnTimePackages') * 100 / ph).otherwise(None))\n",
    "        .round(2).alias('OnTimeDeliveryRate (%)'),\n",
    "\n",
    "        (pl.when(ti > 0).then(pl.col('TotalIncidentCost') / ti).otherwise(0.0))\n",
    "        .round(2).alias('AverageCostPerIncident (€)')\n",
    "    ]).drop([\n",
    "        'TotalBadPackages',\n",
    "        'TotalOnTimePackages',\n",
    "        'TotalIncidentCost'\n",
    "    ])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz7f_w9i7yOS"
   },
   "source": [
    "## File reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading all the main data files so we can work with the information. This step brings together data from different sources into our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 15140,
     "status": "ok",
     "timestamp": 1748834422070,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "JHwC_pv27jgP"
   },
   "outputs": [],
   "source": [
    "df_density_report       = polars_read_excel(PATH_DENSITY_REPORT)\n",
    "df_historical_incidents = polars_read_excel(PATH_HISTORICAL_INCIDENTS)\n",
    "df_product_attributes   = polars_read_excel(PATH_PRODUCT_ATTRIBUTES)\n",
    "df_supplier_scorecard   = polars_read_excel(PATH_SUPPLIER_SCORECARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sngLbxheFs0s"
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h23cwY4AFwlb"
   },
   "source": [
    "### 1. Density Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start cleaning the density report data to make sure product codes are written correctly and consistently. This helps avoid confusion later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkjOR4F57jgQ"
   },
   "source": [
    "#### 1.1 Product Reference correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1748834422123,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "gw3-Gu1z-Ta3"
   },
   "outputs": [],
   "source": [
    "df_density_report = clean_product_reference_column(df_density_report, \"ProductReference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4fKCXnSh8N-"
   },
   "source": [
    "#### 1.2 Naming consistency generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fix names and categories in the data so that similar items are grouped together properly. This ensures consistency across all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1493,
     "status": "ok",
     "timestamp": 1748834423628,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yItquxA2RxXf"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "method_mapping = {\n",
    "    'Methd1': 'Method1',\n",
    "    'Method_2': 'Method2',\n",
    "}\n",
    "\n",
    "layout_mapping = {\n",
    "    'layouta': 'LayoutA',\n",
    "    'LayC': 'LayoutC',\n",
    "}\n",
    "\n",
    "quality_mapping = {\n",
    "    'GOOD': 'Good',\n",
    "    'bad': 'Bad',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'SupplierName', supplier_mapping)\n",
    "\n",
    "# Apply method, layout, and quality mappings\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'ProposedFoldingMethod', method_mapping)\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'ProposedLayout', layout_mapping)\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'PackagingQuality', quality_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDL2cZxXtgBB"
   },
   "source": [
    "#### 1.3 Incorrect input labels modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3108,
     "status": "ok",
     "timestamp": 1748834426720,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yELE07S4agFR"
   },
   "outputs": [],
   "source": [
    "# Define grouping columns\n",
    "group_cols_for_folding = [\n",
    "    \"SupplierName\",\n",
    "    \"GarmentType\",\n",
    "    \"Material\",\n",
    "    \"Weight\",\n",
    "    \"ProposedUnitsPerCarton\",\n",
    "    \"ProposedLayout\",\n",
    "    \"PackagingQuality\"\n",
    "]\n",
    "\n",
    "group_cols_for_layout = [\n",
    "    \"SupplierName\",\n",
    "    \"GarmentType\",\n",
    "    \"Material\",\n",
    "    \"Weight\",\n",
    "    \"ProposedUnitsPerCarton\",\n",
    "    \"ProposedFoldingMethod\",\n",
    "    \"PackagingQuality\"\n",
    "]\n",
    "\n",
    "# Replace invalid values in ProposedFoldingMethod\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedFoldingMethod\",\n",
    "    invalid_values=[\"FoldX\", \"None\"],\n",
    "    group_cols=group_cols_for_folding\n",
    ")\n",
    "\n",
    "# Replace invalid values in ProposedLayout\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedLayout\",\n",
    "    invalid_values=[\"Box9\", \"LayoutX\"],\n",
    "    group_cols=group_cols_for_layout\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X9-o6dzaEwL"
   },
   "source": [
    "#### 1.4 Drop incorrect values of number of units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify and correct any unusual or invalid entries in the data by replacing them with more appropriate values based on similar records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1748834426762,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "d5jd38jmaEwL"
   },
   "outputs": [],
   "source": [
    "# Clean ProposedUnitsPerCarton: set invalid values to null\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") <= 0) |\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") % 1 != 0) |\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") > 100)\n",
    "    )\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"ProposedUnitsPerCarton\"))\n",
    "    .alias(\"ProposedUnitsPerCarton\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjEfI6mnUI5_"
   },
   "source": [
    "### 2. Historical Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7rEeXM3lOYE"
   },
   "source": [
    "#### 2.1 Product Reference correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1748834426819,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "ENUv-HL_lQpG"
   },
   "outputs": [],
   "source": [
    "df_historical_incidents = clean_product_reference_column(df_historical_incidents, \"ProductReference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nofHuxBblkaz"
   },
   "source": [
    "#### 2.2 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748834426822,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "jhg7isrHllex"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_historical_incidents = clean_column_with_mapping(df_historical_incidents, 'SupplierName', supplier_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4vmAYqoVHzI"
   },
   "source": [
    "### 3. Product Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBaiu_s6Wk7w"
   },
   "source": [
    "No further cleaning of this dataset is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNl3APC6WmW9"
   },
   "source": [
    "### 4. Supplier Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OBohECZmjiL"
   },
   "source": [
    "#### 4.1 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1748834426840,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "DR9Dx3r_mifw"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_supplier_scorecard = clean_column_with_mapping(df_supplier_scorecard, 'SupplierName', supplier_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdtzQZ0bo13R"
   },
   "source": [
    "#### 4.2 Grouping correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine supplier performance data into a clearer summary that shows how each supplier is performing over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748834426846,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "i4xyawX2o0b6"
   },
   "outputs": [],
   "source": [
    "df_supplier_scorecard_agg = aggregate_supplier_scorecard(df_supplier_scorecard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6E6RwcJh8Pp"
   },
   "source": [
    "### 5. Export separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the cleaned data to new files so that all the improvements we made are preserved and ready for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73560,
     "status": "ok",
     "timestamp": 1748834500409,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "8D7V4kjbqNjm",
    "outputId": "23432de4-1a7b-4cf3-c692-13b6ddc9628e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x7c6e78c4b210>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_density_report.write_excel(EXPORT_DENSITY_REPORT)\n",
    "df_historical_incidents.write_excel(EXPORT_HISTORICAL_INCIDENTS)\n",
    "df_product_attributes.write_excel(EXPORT_PRODUCT_ATTRIBUTES)\n",
    "df_supplier_scorecard.write_excel(EXPORT_SUPPLIER_SCORECARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU0WR4BQrvBm"
   },
   "source": [
    "## Dataframe integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtkTkq3UvDYO"
   },
   "source": [
    "### 1. Nulls filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before combining datasets, we filter out incomplete records to ensure we only work with complete, reliable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1748834500414,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "hvgpXvDIrxGn"
   },
   "outputs": [],
   "source": [
    "df_density_report_join = df_density_report.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null() &\n",
    "    pl.col(\"ProposedUnitsPerCarton\").is_not_null() &\n",
    "    pl.col(\"ProposedFoldingMethod\").is_not_null() &\n",
    "    pl.col(\"ProposedLayout\").is_not_null()\n",
    ")\n",
    "\n",
    "df_historical_incidents_join = df_historical_incidents.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null()\n",
    ")\n",
    "\n",
    "df_product_attributes_join = df_product_attributes.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null()\n",
    ")\n",
    "\n",
    "df_supplier_scorecard_join = df_supplier_scorecard_agg.filter(\n",
    "    pl.col(\"SupplierName\").is_not_null()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EydBEf9mviUs"
   },
   "source": [
    "### 2. Dataframes joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU0Qt4acm_Pa"
   },
   "source": [
    "#### 2.1 Dataframes joining (Product Attributes & Scorecard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine all our cleaned datasets into one master file that contains all the information we need for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6948,
     "status": "ok",
     "timestamp": 1748834507365,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "19D0LYivvhMv"
   },
   "outputs": [],
   "source": [
    "df_full_join = df_density_report_join.join(\n",
    "    df_product_attributes_join.select([\"ProductReference\", \"Size\", \"Collection\"]),\n",
    "    on=\"ProductReference\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# We create a new column to join with the scorecard dataframe\n",
    "df_full_join = df_full_join.with_columns(\n",
    "    pl.col(\"DateOfReport\").map_elements(\n",
    "        lambda d: (d - relativedelta(months=1)).strftime(\"%Y-%m\"),\n",
    "        return_dtype=pl.Utf8\n",
    "    ).alias(\"PreviousMonth\")\n",
    ")\n",
    "\n",
    "df_full_join = df_full_join.join(\n",
    "    df_supplier_scorecard_join,\n",
    "    left_on=[\"SupplierName\", \"PreviousMonth\"],\n",
    "    right_on=[\"SupplierName\", \"Month\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRYJAtZEnFFq"
   },
   "source": [
    "#### 2.2 Dataframes joining (Historical Incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1748834507491,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "iKa0VgjyofE7"
   },
   "outputs": [],
   "source": [
    "# Add unique ID to incidents\n",
    "df_incidents = (\n",
    "    df_historical_incidents.with_row_index(name='IncidentID_AutoGen')\n",
    ")\n",
    "\n",
    "# Filter incident candidates within 14 days after report\n",
    "df_candidates = (\n",
    "    df_density_report_join.join(df_incidents, on=[\"ProductReference\", \"SupplierName\"], how=\"inner\")\n",
    "    .filter(\n",
    "        (pl.col(\"DateOfIncident\") >= pl.col(\"DateOfReport\")) &\n",
    "        (pl.col(\"DateOfIncident\") <= pl.col(\"DateOfReport\") + pl.duration(days=14))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Deduplicate - one best match per incident\n",
    "df_report_to_incident = (\n",
    "    df_candidates.with_columns(\n",
    "        (pl.col(\"DateOfIncident\") - pl.col(\"DateOfReport\")).dt.total_days().alias(\"days_lag\")\n",
    "    )\n",
    "    .sort(['IncidentID_AutoGen', \"days_lag\", \"DateOfReport\", \"ReportID\"])\n",
    "    .group_by('IncidentID_AutoGen', maintain_order=True)\n",
    "    .first()\n",
    "    if df_candidates.height > 0 else pl.DataFrame()\n",
    ")\n",
    "\n",
    "# Join to full dataset\n",
    "incident_cols = ['IncidentID_AutoGen', 'DateOfIncident', 'CostImpact (€)', 'IssueDescription', 'ResolutionStatus']\n",
    "df_full_join = df_full_join.join(\n",
    "    df_report_to_incident.select([\"ReportID\"] + [col for col in incident_cols if col in df_report_to_incident.columns]),\n",
    "    on=\"ReportID\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nays8JT93MEg"
   },
   "source": [
    "### 3. Dataframes joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the complete integrated dataset that will be used to train our machine learning models and generate insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124344,
     "status": "ok",
     "timestamp": 1748834631844,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "c3XHEhpT3RyX",
    "outputId": "164cf3e8-9b4e-4456-9c8d-8c961e290cba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x7c6e6d9a8410>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_join.write_excel(EXPORT_FULL_JOIN)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nBARle-BiX4b",
    "l751Y4pzFSGQ",
    "tKxU3mwf_4BN",
    "uKHEnncl_-YM",
    "kbmzxdzCUiR8",
    "WZ_hUhl5x3pr",
    "Zpo3gFfBar6l",
    "e5zgJF_NaEwB",
    "YQmXcW2oaEwG",
    "kz7f_w9i7yOS",
    "wkjOR4F57jgQ",
    "E4fKCXnSh8N-",
    "bDL2cZxXtgBB",
    "6X9-o6dzaEwL",
    "Z7rEeXM3lOYE",
    "nofHuxBblkaz",
    "8OBohECZmjiL",
    "KdtzQZ0bo13R",
    "GtkTkq3UvDYO",
    "EydBEf9mviUs",
    "nays8JT93MEg"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
