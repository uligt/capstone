{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_9nryk7DPtX"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBARle-BiX4b"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9924,
     "status": "ok",
     "timestamp": 1746679554198,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "UDa2w5NgiZKW",
    "outputId": "a24b02f5-95ca-4388-f6fd-ba3e7d34816f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastexcel in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (from fastexcel) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (from pyarrow>=8.0.0->fastexcel) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastexcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-91n0nF9meD"
   },
   "source": [
    "Side note: It will be useful to put all the required libraries in a requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1746679555812,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "Z_JWQ-EZFOd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l751Y4pzFSGQ"
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1746679555819,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "2r_OfAHoFWCq"
   },
   "outputs": [],
   "source": [
    "PATH_DENSITY_REPORT       = 'DensityReports.xlsx'\n",
    "PATH_HISTORICAL_INCIDENTS = 'HistoricalIncidents.xlsx'\n",
    "PATH_PRODUCT_ATTRIBUTES   = 'ProductAttributes.xlsx'\n",
    "PATH_SUPPLIER_SCORECARD   = 'SupplierScorecard.xlsx'\n",
    "\n",
    "EXPORT_DENSITY_REPORT       = 'density_report.csv'\n",
    "EXPORT_HISTORICAL_INCIDENTS = 'historical_incidents.csv'\n",
    "EXPORT_PRODUCT_ATTRIBUTES   = 'product_attributes.csv'\n",
    "EXPORT_SUPPLIER_SCORECARD   = 'supplier_scorecard.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZpkTTkwilQu"
   },
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKxU3mwf_4BN"
   },
   "source": [
    "### 1. Read excel files with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746679555833,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "zut0lQNJioXd"
   },
   "outputs": [],
   "source": [
    "def polars_read_excel(file_name, sheet_name='Sheet1'):\n",
    "  return pl.read_excel(source=file_name, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKHEnncl_-YM"
   },
   "source": [
    "### 2. Removing invalid strings in Product Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746679555847,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "trr2YqLyAbRk"
   },
   "outputs": [],
   "source": [
    "def clean_product_reference(series, valid_pattern = r\"^PRD\\d{5}$\"):\n",
    "  # Convert all the series to text format\n",
    "  series_string = series.cast(pl.Utf8, strict=False)\n",
    "\n",
    "  # Removes any \"X\" character at the end of the string\n",
    "  cleaned_series = series_string.str.strip_chars_end('X')\n",
    "\n",
    "  # Deterine if the data has a valid structure\n",
    "  is_valid = cleaned_series.str.contains(valid_pattern)\n",
    "\n",
    "  # Convert to None all invalid strings in the data\n",
    "  return pl.when(is_valid).then(cleaned_series).otherwise(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbmzxdzCUiR8"
   },
   "source": [
    "### 3. Modify column based on a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746679555852,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "HhAcOJM4Ug0s"
   },
   "outputs": [],
   "source": [
    "def clean_column_with_mapping(col_name, mapping_dict):\n",
    "  return (\n",
    "        pl.col(col_name)\n",
    "          .cast(pl.Utf8, strict=False)\n",
    "          .str.strip_chars()\n",
    "          .str.replace_all(\" \", \"\")\n",
    "          .map_elements(lambda val: mapping_dict.get(val, val), return_dtype=pl.Utf8)\n",
    "          .alias(col_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ_hUhl5x3pr"
   },
   "source": [
    "### 4. Most frequent combination of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746679555856,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "5HMa-ZVqx3Eg"
   },
   "outputs": [],
   "source": [
    "def most_common_combination(df, group_cols, additional_cols=[]):\n",
    "  return (\n",
    "      df\n",
    "      .group_by(group_cols + additional_cols)\n",
    "      .agg(pl.len().alias(\"count\"))\n",
    "      .sort(group_cols + [\"count\"], descending=[False] * len(group_cols) + [True])\n",
    "      .unique(subset=group_cols, keep='first')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpo3gFfBar6l"
   },
   "source": [
    "### 5. Replace invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uVZ-rF7rasTE"
   },
   "outputs": [],
   "source": [
    "def replace_invalid_values(df: pl.DataFrame,\n",
    "                           target_col: str,\n",
    "                           invalid_values: list[str],\n",
    "                           group_cols: list[str]):\n",
    "\n",
    "    # Compute most common valid values\n",
    "    df_most_common = most_common_combination(\n",
    "        df.filter(~pl.col(target_col).is_in(invalid_values)),\n",
    "        group_cols,\n",
    "        additional_cols=[target_col]\n",
    "    )\n",
    "\n",
    "    # Replace each invalid value\n",
    "    fixed_parts = []\n",
    "    for val in invalid_values:\n",
    "        df_invalid = df.filter(pl.col(target_col) == val)\n",
    "        df_replaced = (\n",
    "            df_invalid.drop(target_col)\n",
    "            .join(\n",
    "                df_most_common.select(group_cols + [target_col]),\n",
    "                on=group_cols,\n",
    "                how=\"left\"\n",
    "            )\n",
    "        )\n",
    "        fixed_parts.append(df_replaced)\n",
    "\n",
    "    # Keep valid rows\n",
    "    df_cleaned = df.filter(~pl.col(target_col).is_in(invalid_values))\n",
    "\n",
    "    # Align column order and merge all\n",
    "    column_order = df_cleaned.columns\n",
    "    fixed_parts = [part.select(column_order) for part in fixed_parts]\n",
    "\n",
    "    return pl.concat([df_cleaned] + fixed_parts, how=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Sentinel Values for `UnitsPerCarton`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_units_per_carton_median(df_input: pl.DataFrame) -> pl.DataFrame:\n",
    "    median_map_garment = (\n",
    "        df_input.filter(pl.col('ProposedUnitsPerCarton').is_not_null() & pl.col('GarmentType').is_not_null())\n",
    "        .group_by('GarmentType')\n",
    "        .agg(pl.median('ProposedUnitsPerCarton').alias('MedianUnits_Garment'))\n",
    "    )\n",
    "\n",
    "    global_valid_median = df_input.filter(\n",
    "        pl.col('ProposedUnitsPerCarton').is_not_null()\n",
    "    )['ProposedUnitsPerCarton'].median()\n",
    "\n",
    "    if global_valid_median is None: \n",
    "        global_valid_median = 0 \n",
    "\n",
    "    df_with_medians = df_input.join(\n",
    "        median_map_garment, on='GarmentType', how='left' \n",
    "    )\n",
    "\n",
    "    df_imputed = df_with_medians.with_columns(\n",
    "        pl.coalesce(\n",
    "            pl.col('ProposedUnitsPerCarton'),\n",
    "            pl.col('MedianUnits_Garment'),\n",
    "            pl.lit(global_valid_median) \n",
    "        ).alias('ProposedUnitsPerCarton')\n",
    "    ).drop(['MedianUnits_Garment']) \n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. `Supplier Scorecard` aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_supplier_scorecard(df_scorecard: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Step 1: Aggregate raw sums and components for weighted averages\n",
    "    df_aggregated = df_scorecard.group_by(['SupplierName', 'Month']).agg(\n",
    "        pl.sum('PackagesHandled').alias('PackagesHandled'),\n",
    "        pl.sum('TotalIncidents').alias('TotalIncidents'),\n",
    "        pl.sum('AnomaliesDetected').alias('AnomaliesDetected'), \n",
    "        (pl.col('PackagesHandled') * pl.col('BadPackagingRate (%)') / 100.0).sum().alias('TotalBadPackages'),\n",
    "        (pl.col('PackagesHandled') * pl.col('OnTimeDeliveryRate (%)') / 100.0).sum().alias('TotalOnTimePackages'),\n",
    "        (pl.col('AverageCostPerIncident (€)') * pl.col('TotalIncidents')).sum().alias('TotalIncidentCost')\n",
    "    )\n",
    "\n",
    "    # Step 2: Calculate final rates and average costs\n",
    "    df_calculated = df_aggregated.with_columns(\n",
    "        (pl.when(pl.col('PackagesHandled') > 0)\n",
    "         .then((pl.col('TotalBadPackages') * 100.0) / pl.col('PackagesHandled'))\n",
    "         .otherwise(0.0) \n",
    "        ).alias('BadPackagingRate (%)'),\n",
    "\n",
    "        (pl.when(pl.col('PackagesHandled') > 0)\n",
    "         .then((pl.col('TotalOnTimePackages') * 100.0) / pl.col('PackagesHandled'))\n",
    "         .otherwise(None) \n",
    "        ).alias('OnTimeDeliveryRate (%)'),\n",
    "\n",
    "        (pl.when(pl.col('TotalIncidents') > 0)\n",
    "         .then(pl.col('TotalIncidentCost') / pl.col('TotalIncidents'))\n",
    "         .otherwise(0.0) \n",
    "        ).alias('AverageCostPerIncident (€)')\n",
    "    )\n",
    "\n",
    "    # Step 3: Round calculated metrics\n",
    "    df_rounded = df_calculated.with_columns(\n",
    "        pl.col('BadPackagingRate (%)').round(2),\n",
    "        pl.col('OnTimeDeliveryRate (%)').round(2),\n",
    "        pl.col('AverageCostPerIncident (€)').round(2)\n",
    "    )\n",
    "\n",
    "    # Step 4: Drop intermediate columns used for calculation\n",
    "    df_final = df_rounded.drop([\n",
    "        'TotalBadPackages',\n",
    "        'TotalOnTimePackages',\n",
    "        'TotalIncidentCost'\n",
    "    ])\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz7f_w9i7yOS"
   },
   "source": [
    "## File reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1746682861592,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "JHwC_pv27jgP"
   },
   "outputs": [],
   "source": [
    "df_density_report      = polars_read_excel(PATH_DENSITY_REPORT)\n",
    "df_historical_incidents = polars_read_excel(PATH_HISTORICAL_INCIDENTS)\n",
    "df_product_attributes   = polars_read_excel(PATH_PRODUCT_ATTRIBUTES)\n",
    "df_supplier_scorecard   = polars_read_excel(PATH_SUPPLIER_SCORECARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sngLbxheFs0s"
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h23cwY4AFwlb"
   },
   "source": [
    "## 1. Density Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkjOR4F57jgQ"
   },
   "source": [
    "### 1.1 Product Reference correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1746682861629,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "gw3-Gu1z-Ta3"
   },
   "outputs": [],
   "source": [
    "df_density_report = df_density_report.with_columns(\n",
    "    clean_product_reference(pl.col(\"ProductReference\")).alias(\"ProductReference\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1746682930409,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "sJnsk53SAvYg",
    "outputId": "7d07b61d-53da-4a23-9e29-2367cdbd5963"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ProposedFoldingMethod</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;FoldX&quot;</td><td>2426</td></tr><tr><td>&quot;Methd1&quot;</td><td>2450</td></tr><tr><td>&quot;Method1&quot;</td><td>157652</td></tr><tr><td>&quot;Method2&quot;</td><td>218201</td></tr><tr><td>&quot;Method3&quot;</td><td>114363</td></tr><tr><td>&quot;Method_2&quot;</td><td>2394</td></tr><tr><td>&quot;None&quot;</td><td>2514</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────────────────────┬────────┐\n",
       "│ ProposedFoldingMethod ┆ len    │\n",
       "│ ---                   ┆ ---    │\n",
       "│ str                   ┆ u32    │\n",
       "╞═══════════════════════╪════════╡\n",
       "│ FoldX                 ┆ 2426   │\n",
       "│ Methd1                ┆ 2450   │\n",
       "│ Method1               ┆ 157652 │\n",
       "│ Method2               ┆ 218201 │\n",
       "│ Method3               ┆ 114363 │\n",
       "│ Method_2              ┆ 2394   │\n",
       "│ None                  ┆ 2514   │\n",
       "└───────────────────────┴────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_density_report.group_by(pl.col('ProposedFoldingMethod')).len().sort('ProposedFoldingMethod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4fKCXnSh8N-"
   },
   "source": [
    "### 1.2 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1746682862233,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yItquxA2RxXf"
   },
   "outputs": [],
   "source": [
    "# We define the dictionary of values we want to change in suppliers\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "# We modify the Supplier column in density_report\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    clean_column_with_mapping('SupplierName', supplier_mapping)\n",
    ")\n",
    "\n",
    "# Apply to df_historical_incidents\n",
    "df_historical_incidents = df_historical_incidents.with_columns(\n",
    "    clean_column_with_mapping('SupplierName', supplier_mapping)\n",
    ")\n",
    "\n",
    "# Apply to df_supplier_scorecard\n",
    "df_supplier_scorecard = df_supplier_scorecard.with_columns(\n",
    "    clean_column_with_mapping('SupplierName', supplier_mapping)\n",
    ")\n",
    "\n",
    "# We define the dictionary of values we want to change in method\n",
    "method_mapping = {\n",
    "    'Methd1': 'Method1',\n",
    "    'Method_2': 'Method2',\n",
    "}\n",
    "\n",
    "# We modify the Folding Method column\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    clean_column_with_mapping('ProposedFoldingMethod', method_mapping)\n",
    ")\n",
    "\n",
    "# We define the dictionary of values we want to change in layout\n",
    "layout_mapping = {\n",
    "    'layouta': 'LayoutA',\n",
    "    'LayC': 'LayoutC',\n",
    "}\n",
    "\n",
    "# We modify the Proposed Layout column\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    clean_column_with_mapping('ProposedLayout', layout_mapping)\n",
    ")\n",
    "\n",
    "# We define the dictionary of values we want to change in quality\n",
    "quality_mapping = {\n",
    "    'GOOD': 'Good',\n",
    "    'bad': 'Bad',\n",
    "}\n",
    "\n",
    "# We modify the Packaging Quality column\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    clean_column_with_mapping('PackagingQuality', quality_mapping)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDL2cZxXtgBB"
   },
   "source": [
    "### 1.3 Incorrect input labels modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1746682910737,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yELE07S4agFR"
   },
   "outputs": [],
   "source": [
    "# Fix ProposedFoldingMethod\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedFoldingMethod\",\n",
    "    invalid_values=[\"FoldX\", \"None\"],\n",
    "    group_cols=[\n",
    "        \"SupplierName\",\n",
    "        \"GarmentType\",\n",
    "        \"Material\",\n",
    "        \"Weight\",\n",
    "        \"ProposedUnitsPerCarton\",\n",
    "        \"ProposedLayout\",\n",
    "        \"PackagingQuality\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fix ProposedLayout\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedLayout\",\n",
    "    invalid_values=[\"Box9\", \"LayoutX\"],\n",
    "    group_cols=[\n",
    "        \"SupplierName\",\n",
    "        \"GarmentType\",\n",
    "        \"Material\",\n",
    "        \"Weight\",\n",
    "        \"ProposedUnitsPerCarton\",\n",
    "        \"ProposedFoldingMethod\",\n",
    "        \"PackagingQuality\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Outliers in `ProposedUnitsPerCarton`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count in ProposedUnitsPerCarton after sentinel removal: 11297\n",
      "Null count in ProposedUnitsPerCarton after imputation: 0\n",
      "shape: (9, 2)\n",
      "┌────────────┬────────────────────────┐\n",
      "│ statistic  ┆ ProposedUnitsPerCarton │\n",
      "│ ---        ┆ ---                    │\n",
      "│ str        ┆ f64                    │\n",
      "╞════════════╪════════════════════════╡\n",
      "│ count      ┆ 500000.0               │\n",
      "│ null_count ┆ 0.0                    │\n",
      "│ mean       ┆ 24.75393               │\n",
      "│ std        ┆ 11.169403              │\n",
      "│ min        ┆ 0.0                    │\n",
      "│ 25%        ┆ 16.0                   │\n",
      "│ 50%        ┆ 25.0                   │\n",
      "│ 75%        ┆ 32.0                   │\n",
      "│ max        ┆ 49.0                   │\n",
      "└────────────┴────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Define the sentinel values\n",
    "invalid_codes_units = [-3.0, 9999.0, 12.5] \n",
    "\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    pl.when(pl.col('ProposedUnitsPerCarton').is_in(invalid_codes_units))\n",
    "    .then(None) \n",
    "    .otherwise(pl.col('ProposedUnitsPerCarton'))\n",
    "    .alias('ProposedUnitsPerCarton')\n",
    ")\n",
    "\n",
    "print(f\"Null count in ProposedUnitsPerCarton after sentinel removal: {df_density_report['ProposedUnitsPerCarton'].is_null().sum()}\")\n",
    "\n",
    "# Step 2: Impute all nulls in ProposedUnitsPerCarton\n",
    "df_density_report = impute_units_per_carton_median(df_density_report.clone()) \n",
    "\n",
    "print(f\"Null count in ProposedUnitsPerCarton after imputation: {df_density_report['ProposedUnitsPerCarton'].is_null().sum()}\")\n",
    "print(df_density_report.select('ProposedUnitsPerCarton').describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjEfI6mnUI5_"
   },
   "source": [
    "## 2. Historical Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1DjgDh3h8PW"
   },
   "source": [
    "No further cleaning of this dataset is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4vmAYqoVHzI"
   },
   "source": [
    "## 3. Product Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBaiu_s6Wk7w"
   },
   "source": [
    "No further cleaning of this dataset is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNl3APC6WmW9"
   },
   "source": [
    "## 4. Supplier Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA61ApHt7jgb"
   },
   "source": [
    "### Data Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supplier_scorecard = aggregate_supplier_scorecard(df_supplier_scorecard.clone()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6E6RwcJh8Pp"
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jnJWbLRWX6x-"
   },
   "outputs": [],
   "source": [
    "df_density_report.write_csv(EXPORT_DENSITY_REPORT, separator=\";\")\n",
    "df_historical_incidents.write_csv(EXPORT_HISTORICAL_INCIDENTS, separator=\";\")\n",
    "df_product_attributes.write_csv(EXPORT_PRODUCT_ATTRIBUTES, separator=\";\")\n",
    "df_supplier_scorecard.write_csv(EXPORT_SUPPLIER_SCORECARD, separator=\";\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
