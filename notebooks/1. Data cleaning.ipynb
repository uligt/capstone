{"cells":[{"cell_type":"markdown","metadata":{"id":"E_9nryk7DPtX"},"source":["# Data cleaning"]},{"cell_type":"markdown","source":["## Necessary libraries"],"metadata":{"id":"nBARle-BiX4b"}},{"cell_type":"code","source":["pip install fastexcel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDa2w5NgiZKW","executionInfo":{"status":"ok","timestamp":1746248789560,"user_tz":300,"elapsed":9251,"user":{"displayName":"Francisco","userId":"11190877053062531761"}},"outputId":"25ecbb6e-1df9-4b79-9cd2-43a576f50a8a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fastexcel\n","  Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n","Downloading fastexcel-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fastexcel\n","Successfully installed fastexcel-0.14.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"GJHWKhpBFLSZ"},"source":["## Libraries import"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1722,"status":"ok","timestamp":1746248791290,"user":{"displayName":"Francisco","userId":"11190877053062531761"},"user_tz":300},"id":"Z_JWQ-EZFOd0"},"outputs":[],"source":["import pandas as pd\n","import polars as pl"]},{"cell_type":"markdown","metadata":{"id":"l751Y4pzFSGQ"},"source":["## Global variables"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1746248814499,"user":{"displayName":"Francisco","userId":"11190877053062531761"},"user_tz":300},"id":"2r_OfAHoFWCq"},"outputs":[],"source":["PATH_DENSITY_REPORT       = 'DensityReports.xlsx'\n","PATH_HISTORICAL_INCIDENTS = 'HistoricalIncidents.xlsx'\n","PATH_PRODUCT_ATTRIBUTES   = 'ProductAttributes.xlsx'\n","PATH_SUPPLIER_SCORECARD   = 'SupplierScorecard.xlsx'\n","\n","EXPORT_DENSITY_REPORT       = 'density_report.csv'\n","EXPORT_HISTORICAL_INCIDENTS = 'historical_incidents.csv'\n","EXPORT_PRODUCT_ATTRIBUTES   = 'product_attributes.csv'\n","EXPORT_SUPPLIER_SCORECARD   = 'supplier_scorecard.csv'"]},{"cell_type":"markdown","source":["## Global functions"],"metadata":{"id":"JZpkTTkwilQu"}},{"cell_type":"markdown","source":["### 1. Read excel file with Polars"],"metadata":{"id":"NpEw4cHDim_z"}},{"cell_type":"code","source":["def polars_read_excel(file_name, sheet_name='Sheet1'):\n","  return pl.read_excel(source=file_name, sheet_name=sheet_name)"],"metadata":{"id":"zut0lQNJioXd","executionInfo":{"status":"ok","timestamp":1746248833876,"user_tz":300,"elapsed":13,"user":{"displayName":"Francisco","userId":"11190877053062531761"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sngLbxheFs0s"},"source":["## Execution"]},{"cell_type":"markdown","metadata":{"id":"h23cwY4AFwlb"},"source":["## 1. Density Report"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"LeHB-bzIh8N6","executionInfo":{"status":"ok","timestamp":1746248914621,"user_tz":300,"elapsed":8374,"user":{"displayName":"Francisco","userId":"11190877053062531761"}},"outputId":"7ec015e2-9e21-40ea-b0ee-51c4eaca12bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["shape: (5, 11)\n","┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n","│ ReportID  ┆ ProductRe ┆ DateOfRep ┆ SupplierN ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packagin │\n","│ ---       ┆ ference   ┆ ort       ┆ ame       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ gQuality │\n","│ str       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---      │\n","│           ┆ str       ┆ date      ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ str      │\n","│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆           ┆          │\n","╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n","│ RPT000000 ┆ PRD07271  ┆ 2024-03-0 ┆ SupplierA ┆ … ┆ 29.0      ┆ Method2   ┆ LayoutC   ┆ Good     │\n","│ 1         ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD00861  ┆ 2024-05-2 ┆ SupplierC ┆ … ┆ 20.0      ┆ Method2   ┆ LayoutB   ┆ Good     │\n","│ 2         ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05391  ┆ 2023-11-1 ┆ SupplierA ┆ … ┆ 31.0      ┆ Method1   ┆ LayoutA   ┆ Good     │\n","│ 3         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05192  ┆ 2024-06-1 ┆ SupplierA ┆ … ┆ 5.0       ┆ Method1   ┆ LayoutD   ┆ Good     │\n","│ 4         ┆           ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05735  ┆ 2023-07-1 ┆ SupplierA ┆ … ┆ 9.0       ┆ Method2   ┆ LayoutD   ┆ Good     │\n","│ 5         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ReportID</th><th>ProductReference</th><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th><th>PackagingQuality</th></tr><tr><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;RPT0000001&quot;</td><td>&quot;PRD07271&quot;</td><td>2024-03-04</td><td>&quot;SupplierA&quot;</td><td>&quot;Pants&quot;</td><td>&quot;Polyester&quot;</td><td>0.35</td><td>29.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutC&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000002&quot;</td><td>&quot;PRD00861&quot;</td><td>2024-05-27</td><td>&quot;SupplierC&quot;</td><td>&quot;T-Shirt&quot;</td><td>&quot;Denim&quot;</td><td>0.21</td><td>20.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutB&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000003&quot;</td><td>&quot;PRD05391&quot;</td><td>2023-11-18</td><td>&quot;SupplierA&quot;</td><td>&quot;Shirt&quot;</td><td>&quot;Cotton&quot;</td><td>0.2</td><td>31.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutA&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000004&quot;</td><td>&quot;PRD05192&quot;</td><td>2024-06-13</td><td>&quot;SupplierA&quot;</td><td>&quot;Coat&quot;</td><td>&quot;Cotton&quot;</td><td>1.3</td><td>5.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutD&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000005&quot;</td><td>&quot;PRD05735&quot;</td><td>2023-07-18</td><td>&quot;SupplierA&quot;</td><td>&quot;Coat&quot;</td><td>&quot;Polyester&quot;</td><td>1.11</td><td>9.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutD&quot;</td><td>&quot;Good&quot;</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":6}],"source":["# Read density report file with Polars\n","df_density_report = polars_read_excel(PATH_DENSITY_REPORT)\n","\n","# we will check the first rows of the file\n","df_density_report.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"B4EHqQWth8N8","executionInfo":{"status":"ok","timestamp":1746248925822,"user_tz":300,"elapsed":5,"user":{"displayName":"Francisco","userId":"11190877053062531761"}},"outputId":"144e372c-8ea0-46ce-92a8-9c7fd1dafd5b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["shape: (9, 12)\n","┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n","│ statistic ┆ ReportID  ┆ ProductRe ┆ DateOfRep ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packagin │\n","│ ---       ┆ ---       ┆ ference   ┆ ort       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ gQuality │\n","│ str       ┆ str       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---      │\n","│           ┆           ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ str      │\n","│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆           ┆          │\n","╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n","│ count     ┆ 500000    ┆ 500000    ┆ 500000    ┆ … ┆ 500000.0  ┆ 500000    ┆ 500000    ┆ 500000   │\n","│ null_coun ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0.0       ┆ 0         ┆ 0         ┆ 0        │\n","│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ mean      ┆ null      ┆ null      ┆ 2023-09-3 ┆ … ┆ 99.981055 ┆ null      ┆ null      ┆ null     │\n","│           ┆           ┆           ┆ 0 15:58:4 ┆   ┆           ┆           ┆           ┆          │\n","│           ┆           ┆           ┆ 7.712000  ┆   ┆           ┆           ┆           ┆          │\n","│ std       ┆ null      ┆ null      ┆ null      ┆ … ┆ 864.74101 ┆ null      ┆ null      ┆ null     │\n","│           ┆           ┆           ┆           ┆   ┆ 6         ┆           ┆           ┆          │\n","│ min       ┆ RPT000000 ┆ PRD00     ┆ 2023-01-0 ┆ … ┆ -3.0      ┆ FoldX     ┆ Box9      ┆ Bad      │\n","│           ┆ 1         ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆          │\n","│ 25%       ┆ null      ┆ null      ┆ 2023-05-1 ┆ … ┆ 16.0      ┆ null      ┆ null      ┆ null     │\n","│           ┆           ┆           ┆ 7         ┆   ┆           ┆           ┆           ┆          │\n","│ 50%       ┆ null      ┆ null      ┆ 2023-09-3 ┆ … ┆ 25.0      ┆ null      ┆ null      ┆ null     │\n","│           ┆           ┆           ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n","│ 75%       ┆ null      ┆ null      ┆ 2024-02-1 ┆ … ┆ 32.0      ┆ null      ┆ null      ┆ null     │\n","│           ┆           ┆           ┆ 4         ┆   ┆           ┆           ┆           ┆          │\n","│ max       ┆ RPT050000 ┆ PRD10000X ┆ 2024-06-3 ┆ … ┆ 9999.0    ┆ None      ┆ layouta   ┆ bad      │\n","│           ┆ 0         ┆           ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n","└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (9, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>ReportID</th><th>ProductReference</th><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th><th>PackagingQuality</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>500000.0</td><td>500000.0</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td><td>&quot;500000&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>&quot;2023-09-30 15:58:47.712000&quot;</td><td>null</td><td>null</td><td>null</td><td>0.461021</td><td>99.981055</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.349694</td><td>864.741016</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;RPT0000001&quot;</td><td>&quot;PRD00&quot;</td><td>&quot;2023-01-01&quot;</td><td>&quot;SPLF&quot;</td><td>&quot;Blouse&quot;</td><td>&quot;Cotton&quot;</td><td>0.08</td><td>-3.0</td><td>&quot;FoldX&quot;</td><td>&quot;Box9&quot;</td><td>&quot;Bad&quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>&quot;2023-05-17&quot;</td><td>null</td><td>null</td><td>null</td><td>0.21</td><td>16.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>&quot;2023-09-30&quot;</td><td>null</td><td>null</td><td>null</td><td>0.33</td><td>25.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>&quot;2024-02-14&quot;</td><td>null</td><td>null</td><td>null</td><td>0.62</td><td>32.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;RPT0500000&quot;</td><td>&quot;PRD10000X&quot;</td><td>&quot;2024-06-30&quot;</td><td>&quot;supplierh&quot;</td><td>&quot;T-Shirt&quot;</td><td>&quot;Wool&quot;</td><td>2.32</td><td>9999.0</td><td>&quot;None&quot;</td><td>&quot;layouta&quot;</td><td>&quot;bad&quot;</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":7}],"source":["df_density_report.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4URHAcZh8N-","outputId":"7846ba25-011c-422f-9ccc-ba992bd678dc"},"outputs":[{"data":{"text/plain":["Schema([('ReportID', String),\n","        ('ProductReference', String),\n","        ('DateOfReport', Datetime(time_unit='ns', time_zone=None)),\n","        ('SupplierName', String),\n","        ('GarmentType', String),\n","        ('Material', String),\n","        ('Weight', Float64),\n","        ('ProposedUnitsPerCarton', Float64),\n","        ('ProposedFoldingMethod', String),\n","        ('ProposedLayout', String),\n","        ('PackagingQuality', String)])"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["# now we will see the structure of the file\n","df_density_report.schema"]},{"cell_type":"markdown","metadata":{"id":"E4fKCXnSh8N-"},"source":["### Naming consistency"]},{"cell_type":"markdown","metadata":{"id":"Y7x882Zdh8N_"},"source":["We will check if there are  grammar errors in columns like `SupplierName`, `GarmentType`, `Material`, `ProposedFoldingMethod`, `ProposedLayout` and `PackagingQuality`to avoid repetition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uecfqqtph8OA","outputId":"69b9fef3-bdad-4dc4-d0f2-72f0e94304fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking Unique Values for Potential Inconsistencies\n","Unique values in: SupplierName\n","['SPLF', 'SuplA', 'SupllierC', 'SuppB', 'SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH', 'supplierA', 'supplierh']\n","Total unique non-null values: 14\n","Unique values in: GarmentType\n","['Blouse', 'Coat', 'Dress', 'Hoodie', 'Jacket', 'Pants', 'Shirt', 'Shorts', 'Skirt', 'Suit', 'Sweater', 'T-Shirt']\n","Total unique non-null values: 12\n","Unique values in: Material\n","['Cotton', 'Denim', 'Linen', 'Polyester', 'Silk', 'Wool']\n","Total unique non-null values: 6\n","Unique values in: ProposedFoldingMethod\n","[None, 'FoldX', 'Methd1', 'Method1', 'Method2', 'Method3', 'Method_2']\n","Total unique non-null values: 6\n","Unique values in: ProposedLayout\n","['Box9', 'LayC', 'LayoutA', 'LayoutB', 'LayoutC', 'LayoutD', 'LayoutE', 'LayoutX', 'layouta']\n","Total unique non-null values: 9\n","Unique values in: PackagingQuality\n","['Bad', 'GOOD', 'Good', 'Uncertain', 'bad']\n","Total unique non-null values: 5\n"]}],"source":["\n","columns_to_check = [\n","    'SupplierName',\n","    'GarmentType',\n","    'Material',\n","    'ProposedFoldingMethod',\n","    'ProposedLayout',\n","    'PackagingQuality']\n","\n","print(\"Checking Unique Values for Potential Inconsistencies\")\n","\n","for col_name in columns_to_check:\n","    if col_name in df_density_report.columns:\n","        try:\n","            unique_values = (\n","                df_density_report[col_name]\n","                .unique()\n","                .sort()\n","            )\n","\n","            print(f\"Unique values in: {col_name}\")\n","            print(unique_values.to_list())\n","            print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")\n","\n","        except Exception as e:\n","            print(f\" Could not process column: {col_name} \")\n","            print(f\"Error: {e}\")\n","    else:\n","        print(f\"Column not found: {col_name}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vjUU-DiKh8OA"},"source":["As we can see, we do have some errors in naming in columns `SupplierName`, `ProposedFoldingMethod`, `ProposedLayout` and `PackagingQuality`. So we need to fix these inconsistencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wr0GO9LOh8OB","outputId":"f3a07269-0fb4-4ebf-9bc8-f3e82cfe7c0e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Unique values in: SupplierName\n","['SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH']\n","Total unique non-null values: 8\n"]}],"source":["#fixing SupplierName\n","supplier_mapping = {\n","    'SuplA': 'SupplierA',\n","    'supplierA': 'SupplierA',\n","    'SuppB': 'SupplierB',\n","    'SupllierC': 'SupplierC',\n","    'SPLF': 'SupplierF',\n","    'supplierh': 'SupplierH',\n","}\n","\n","# Apply the mapping\n","df_density_report = df_density_report.with_columns(\n","    pl.col('SupplierName')\n","      .str.strip_chars()\n","      .replace(supplier_mapping)\n","      .str.replace_all(\" \", \"\")\n","      .alias('SupplierName')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_density_report['SupplierName']\n","    .unique()\n","    .sort()\n",")\n","print(f\" Unique values in: SupplierName\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGV7VCvbh8OB","outputId":"16209a05-a3b9-4ac5-a2b4-a2ace9659fba"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Unique values in: ProposedFoldingMethod\n","[None, 'FoldX', 'Method1', 'Method2', 'Method3']\n","Total unique non-null values: 4\n"]}],"source":["#fixing ProposedFoldingMethod\n","method_mapping = {\n","    'Methd1': 'Method1',\n","    'Method_2': 'Method2',\n","}\n","\n","# Apply the mapping\n","df_density_report = df_density_report.with_columns(\n","    pl.col('ProposedFoldingMethod')\n","      .str.strip_chars()\n","      .replace(method_mapping)\n","      .str.replace_all(\" \", \"\")\n","      .alias('ProposedFoldingMethod')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_density_report['ProposedFoldingMethod']\n","    .unique()\n","    .sort()\n",")\n","print(f\" Unique values in: ProposedFoldingMethod\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVcHKOGMh8OD","outputId":"cc499f3f-4c8a-435f-fb56-bd8f215dd388"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values in: ProposedLayout\n","['Box9', 'LayoutA', 'LayoutB', 'LayoutC', 'LayoutD', 'LayoutE', 'LayoutX']\n","Total unique non-null values: 7\n"]}],"source":["#fixing ProposedLayout\n","layout_mapping = {\n","    'layouta': 'LayoutA',\n","    'LayC': 'LayoutC',\n","}\n","\n","# Apply the mapping\n","df_density_report = df_density_report.with_columns(\n","    pl.col('ProposedLayout')\n","      .str.strip_chars()\n","      .replace(layout_mapping)\n","      .str.replace_all(\" \", \"\")\n","      .alias('ProposedLayout')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_density_report['ProposedLayout']\n","    .unique()\n","    .sort()\n",")\n","print(f\"Unique values in: ProposedLayout\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJ8JfXPjh8OF","outputId":"1a4d01fd-e617-454d-cc1f-5dae375f3a2b"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Unique values in: PackagingQuality\n","['Bad', 'Good', 'Uncertain']\n","Total unique non-null values: 3\n"]}],"source":["#fixing PackagingQuality\n","quality_mapping = {\n","    'GOOD': 'Good',\n","    'bad': 'Bad',\n","}\n","\n","# Apply the mapping\n","df_density_report = df_density_report.with_columns(\n","    pl.col('PackagingQuality')\n","      .str.strip_chars()\n","      .replace(quality_mapping)\n","      .str.replace_all(\" \", \"\")\n","      .alias('PackagingQuality')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_density_report['PackagingQuality']\n","    .unique()\n","    .sort()\n",")\n","print(f\" Unique values in: PackagingQuality\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"markdown","metadata":{"id":"M5HSDPZ9h8OG"},"source":["### Nulls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1BNa2bah8OH","outputId":"c396cf49-981a-4cd2-bf8b-68dcc5cfd22b"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ReportID</th><th>ProductReference</th><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th><th>PackagingQuality</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2514</td><td>0</td><td>0</td></tr></tbody></table></div>"],"text/plain":["shape: (1, 11)\n","┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n","│ ReportID ┆ ProductRe ┆ DateOfRep ┆ SupplierN ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packaging │\n","│ ---      ┆ ference   ┆ ort       ┆ ame       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ Quality   │\n","│ u32      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---       │\n","│          ┆ u32       ┆ u32       ┆ u32       ┆   ┆ ---       ┆ ---       ┆ u32       ┆ u32       │\n","│          ┆           ┆           ┆           ┆   ┆ u32       ┆ u32       ┆           ┆           │\n","╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n","│ 0        ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0         ┆ 2514      ┆ 0         ┆ 0         │\n","└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"]},"execution_count":175,"metadata":{},"output_type":"execute_result"}],"source":["# do we have null values?\n","df_density_report.null_count()"]},{"cell_type":"markdown","metadata":{"id":"3gheP8N0h8OH"},"source":["We only have missing values in 1 column `ProposedFoldingMethod` with **2514** out of 500,000 (around **0.5%** of the data)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ACgnunph8OI","outputId":"080981fc-cf4a-4072-e750-6eab891f301e"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (10, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th></tr><tr><td>datetime[ns]</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2023-01-06 00:00:00</td><td>&quot;SupplierB&quot;</td><td>&quot;Suit&quot;</td><td>&quot;Polyester&quot;</td><td>0.88</td><td>13.0</td><td>null</td><td>&quot;LayoutC&quot;</td></tr><tr><td>2023-10-04 00:00:00</td><td>&quot;SupplierC&quot;</td><td>&quot;Pants&quot;</td><td>&quot;Linen&quot;</td><td>0.44</td><td>22.0</td><td>null</td><td>&quot;LayoutC&quot;</td></tr><tr><td>2024-01-10 00:00:00</td><td>&quot;SupplierB&quot;</td><td>&quot;Pants&quot;</td><td>&quot;Silk&quot;</td><td>0.32</td><td>32.0</td><td>null</td><td>&quot;LayoutC&quot;</td></tr><tr><td>2023-09-10 00:00:00</td><td>&quot;SupplierE&quot;</td><td>&quot;Shirt&quot;</td><td>&quot;Cotton&quot;</td><td>0.18</td><td>49.0</td><td>null</td><td>&quot;LayoutB&quot;</td></tr><tr><td>2024-04-28 00:00:00</td><td>&quot;SupplierA&quot;</td><td>&quot;Shorts&quot;</td><td>&quot;Cotton&quot;</td><td>0.33</td><td>33.0</td><td>null</td><td>&quot;LayoutB&quot;</td></tr><tr><td>2023-10-10 00:00:00</td><td>&quot;SupplierC&quot;</td><td>&quot;Coat&quot;</td><td>&quot;Denim&quot;</td><td>1.88</td><td>8.0</td><td>null</td><td>&quot;LayoutE&quot;</td></tr><tr><td>2023-09-14 00:00:00</td><td>&quot;SupplierE&quot;</td><td>&quot;Shorts&quot;</td><td>&quot;Cotton&quot;</td><td>0.33</td><td>31.0</td><td>null</td><td>&quot;LayoutC&quot;</td></tr><tr><td>2023-05-13 00:00:00</td><td>&quot;SupplierE&quot;</td><td>&quot;Blouse&quot;</td><td>&quot;Polyester&quot;</td><td>0.18</td><td>43.0</td><td>null</td><td>&quot;LayoutB&quot;</td></tr><tr><td>2023-04-26 00:00:00</td><td>&quot;SupplierB&quot;</td><td>&quot;Jacket&quot;</td><td>&quot;Polyester&quot;</td><td>0.67</td><td>19.0</td><td>null</td><td>&quot;LayoutC&quot;</td></tr><tr><td>2024-04-17 00:00:00</td><td>&quot;SupplierA&quot;</td><td>&quot;Dress&quot;</td><td>&quot;Silk&quot;</td><td>0.39</td><td>25.0</td><td>null</td><td>&quot;LayoutB&quot;</td></tr></tbody></table></div>"],"text/plain":["shape: (10, 8)\n","┌────────────┬────────────┬────────────┬───────────┬────────┬────────────┬────────────┬────────────┐\n","│ DateOfRepo ┆ SupplierNa ┆ GarmentTyp ┆ Material  ┆ Weight ┆ ProposedUn ┆ ProposedFo ┆ ProposedLa │\n","│ rt         ┆ me         ┆ e          ┆ ---       ┆ ---    ┆ itsPerCart ┆ ldingMetho ┆ yout       │\n","│ ---        ┆ ---        ┆ ---        ┆ str       ┆ f64    ┆ on         ┆ d          ┆ ---        │\n","│ datetime[n ┆ str        ┆ str        ┆           ┆        ┆ ---        ┆ ---        ┆ str        │\n","│ s]         ┆            ┆            ┆           ┆        ┆ f64        ┆ str        ┆            │\n","╞════════════╪════════════╪════════════╪═══════════╪════════╪════════════╪════════════╪════════════╡\n","│ 2023-01-06 ┆ SupplierB  ┆ Suit       ┆ Polyester ┆ 0.88   ┆ 13.0       ┆ null       ┆ LayoutC    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-10-04 ┆ SupplierC  ┆ Pants      ┆ Linen     ┆ 0.44   ┆ 22.0       ┆ null       ┆ LayoutC    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2024-01-10 ┆ SupplierB  ┆ Pants      ┆ Silk      ┆ 0.32   ┆ 32.0       ┆ null       ┆ LayoutC    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-09-10 ┆ SupplierE  ┆ Shirt      ┆ Cotton    ┆ 0.18   ┆ 49.0       ┆ null       ┆ LayoutB    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2024-04-28 ┆ SupplierA  ┆ Shorts     ┆ Cotton    ┆ 0.33   ┆ 33.0       ┆ null       ┆ LayoutB    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-10-10 ┆ SupplierC  ┆ Coat       ┆ Denim     ┆ 1.88   ┆ 8.0        ┆ null       ┆ LayoutE    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-09-14 ┆ SupplierE  ┆ Shorts     ┆ Cotton    ┆ 0.33   ┆ 31.0       ┆ null       ┆ LayoutC    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-05-13 ┆ SupplierE  ┆ Blouse     ┆ Polyester ┆ 0.18   ┆ 43.0       ┆ null       ┆ LayoutB    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2023-04-26 ┆ SupplierB  ┆ Jacket     ┆ Polyester ┆ 0.67   ┆ 19.0       ┆ null       ┆ LayoutC    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","│ 2024-04-17 ┆ SupplierA  ┆ Dress      ┆ Silk      ┆ 0.39   ┆ 25.0       ┆ null       ┆ LayoutB    │\n","│ 00:00:00   ┆            ┆            ┆           ┆        ┆            ┆            ┆            │\n","└────────────┴────────────┴────────────┴───────────┴────────┴────────────┴────────────┴────────────┘"]},"execution_count":176,"metadata":{},"output_type":"execute_result"}],"source":["#check the column with missing values ProposedFoldingMethod\n","df_density_report.filter(pl.col('ProposedFoldingMethod').is_null()).select(\n","    ['DateOfReport','SupplierName','GarmentType','Material','Weight','ProposedUnitsPerCarton','ProposedFoldingMethod','ProposedLayout']\n",").head(10)"]},{"cell_type":"markdown","metadata":{"id":"O5EvlhoLh8OI"},"source":["Instead of just deleting these rows (and losing data) or picking a random method, we'll make an educated guess based on patterns in the existing data. The most logical assumption is that garments of a similar type, especially when intended for a specific packaging layout are likely folded using the same standard method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZofcTJAKh8OJ","outputId":"0589d22e-cb59-4a6a-d59d-94e0f562b78d"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Mode Folding Method per (GarmentType, ProposedLayout) ---\n","shape: (71, 3)\n","┌─────────────┬────────────────┬────────────────────────────┐\n","│ GarmentType ┆ ProposedLayout ┆ ModeFoldingMethod_Combined │\n","│ ---         ┆ ---            ┆ ---                        │\n","│ str         ┆ str            ┆ str                        │\n","╞═════════════╪════════════════╪════════════════════════════╡\n","│ Skirt       ┆ LayoutX        ┆ Method2                    │\n","│ T-Shirt     ┆ LayoutB        ┆ Method2                    │\n","│ Coat        ┆ LayoutC        ┆ Method3                    │\n","│ Hoodie      ┆ LayoutX        ┆ Method1                    │\n","│ Sweater     ┆ LayoutC        ┆ Method2                    │\n","│ …           ┆ …              ┆ …                          │\n","│ Dress       ┆ LayoutB        ┆ Method2                    │\n","│ Suit        ┆ LayoutB        ┆ Method3                    │\n","│ Skirt       ┆ LayoutA        ┆ Method3                    │\n","│ Skirt       ┆ LayoutC        ┆ Method2                    │\n","│ Shorts      ┆ Box9           ┆ Method2                    │\n","└─────────────┴────────────────┴────────────────────────────┘\n","Number of combined groups found: 71\n","\n","--- Mode Folding Method per GarmentType ---\n","shape: (12, 2)\n","┌─────────────┬───────────────────────────┐\n","│ GarmentType ┆ ModeFoldingMethod_Garment │\n","│ ---         ┆ ---                       │\n","│ str         ┆ str                       │\n","╞═════════════╪═══════════════════════════╡\n","│ Coat        ┆ Method2                   │\n","│ Shirt       ┆ Method2                   │\n","│ Dress       ┆ Method2                   │\n","│ Hoodie      ┆ Method2                   │\n","│ Sweater     ┆ Method2                   │\n","│ …           ┆ …                         │\n","│ T-Shirt     ┆ Method2                   │\n","│ Blouse      ┆ Method2                   │\n","│ Shorts      ┆ Method2                   │\n","│ Suit        ┆ Method2                   │\n","│ Jacket      ┆ Method2                   │\n","└─────────────┴───────────────────────────┘\n","\n","Global Mode Folding Method: Method2\n"]}],"source":["mode_map_combined = (\n","    df_density_report\n","    .filter(pl.col('ProposedFoldingMethod').is_not_null())\n","    .group_by(['GarmentType', 'ProposedLayout'])\n","    .agg(\n","        pl.col('ProposedFoldingMethod').mode().first().alias('ModeFoldingMethod_Combined')\n","    )\n",")\n","\n","print(\"--- Mode Folding Method per (GarmentType, ProposedLayout) ---\")\n","print(mode_map_combined)\n","print(f\"Number of combined groups found: {len(mode_map_combined)}\")\n","\n","\n","# --- Calculate Mode based on GarmentType alone\n","mode_map_garment = (\n","    df_density_report\n","    .filter(pl.col('ProposedFoldingMethod').is_not_null())\n","    .group_by('GarmentType')\n","    .agg(\n","        pl.col('ProposedFoldingMethod').mode().first().alias('ModeFoldingMethod_Garment')\n","    )\n",")\n","print(\"\\n--- Mode Folding Method per GarmentType ---\")\n","print(mode_map_garment)\n","\n","# --- Calculate Global Mode\n","global_mode = df_density_report.filter(\n","    pl.col('ProposedFoldingMethod').is_not_null()\n",")['ProposedFoldingMethod'].mode().first()\n","\n","print(f\"\\nGlobal Mode Folding Method: {global_mode}\")"]},{"cell_type":"markdown","metadata":{"id":"tqM-bKCYh8OJ"},"source":["We can see the typical method used for specific `GarmentType` / `ProposedLayout` pairs. We can see for example 'Method1' was common for `Sweater`/`LayoutX`, while many others used 'Method2'.\n","*   We also see the dominant method for each `GarmentType` individually.\n","*   The overall most frequent method across all known entries was also determined  `Method2`.\n","\n","Now that we've identified these 'best guess' methods based on context, we'll use them to fill in the missing values in the original dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVBogFc7h8OJ","outputId":"890e5214-cfa8-453d-dc1f-1e3520fa2d52"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Null count in ProposedFoldingMethod AFTER imputation: 0\n","Successfully imputed all null values.\n","\n","Example rows that were previously null:\n","shape: (433, 4)\n","┌─────────────────────┬─────────────┬────────────────┬───────────────────────┐\n","│ DateOfReport        ┆ GarmentType ┆ ProposedLayout ┆ ProposedFoldingMethod │\n","│ ---                 ┆ ---         ┆ ---            ┆ ---                   │\n","│ datetime[ns]        ┆ str         ┆ str            ┆ str                   │\n","╞═════════════════════╪═════════════╪════════════════╪═══════════════════════╡\n","│ 2023-01-06 00:00:00 ┆ Suit        ┆ LayoutC        ┆ Method2               │\n","│ 2023-01-06 00:00:00 ┆ Suit        ┆ LayoutC        ┆ Method2               │\n","│ 2023-01-06 00:00:00 ┆ Suit        ┆ LayoutC        ┆ Method1               │\n","│ 2023-01-06 00:00:00 ┆ Suit        ┆ LayoutC        ┆ Method1               │\n","│ 2023-01-06 00:00:00 ┆ Suit        ┆ LayoutC        ┆ Method1               │\n","│ …                   ┆ …           ┆ …              ┆ …                     │\n","│ 2024-04-17 00:00:00 ┆ Dress       ┆ LayoutB        ┆ Method1               │\n","│ 2024-04-17 00:00:00 ┆ Dress       ┆ LayoutB        ┆ Method2               │\n","│ 2024-04-17 00:00:00 ┆ Dress       ┆ LayoutB        ┆ Method2               │\n","│ 2024-04-17 00:00:00 ┆ Dress       ┆ LayoutB        ┆ Method2               │\n","│ 2024-04-17 00:00:00 ┆ Dress       ┆ LayoutB        ┆ Method2               │\n","└─────────────────────┴─────────────┴────────────────┴───────────────────────┘\n"]}],"source":["# Join the calculated modes back to the main dataframe\n","df_impute_step1 = df_density_report.join(\n","    mode_map_combined,\n","    on=['GarmentType', 'ProposedLayout'],\n","    how='left'  # Keep all original rows\n",")\n","\n","df_impute_step2 = df_impute_step1.join(\n","    mode_map_garment,\n","    on='GarmentType',\n","    how='left'\n",")\n","\n","# Impute using coalesce, prioritizing combined, then garment, then global\n","df_imputed = df_impute_step2.with_columns(\n","    pl.coalesce(\n","        pl.col('ProposedFoldingMethod'),\n","        pl.col('ModeFoldingMethod_Combined'),\n","        pl.col('ModeFoldingMethod_Garment'),\n","        pl.lit(global_mode)\n","    ).alias('ProposedFoldingMethod_Imputed')\n",")\n","\n","# Clean up temporary columns\n","df_final_imputed = df_imputed.drop([\n","    'ModeFoldingMethod_Combined',\n","    'ModeFoldingMethod_Garment'\n","])\n","\n","df_final_imputed = df_final_imputed.with_columns(\n","    pl.col('ProposedFoldingMethod_Imputed').alias('ProposedFoldingMethod')\n",").drop('ProposedFoldingMethod_Imputed')\n","\n","\n","# Verify the imputation\n","null_count_after = df_final_imputed['ProposedFoldingMethod'].is_null().sum()\n","print(f\"\\nNull count in ProposedFoldingMethod AFTER imputation: {null_count_after}\")\n","\n","if null_count_after == 0:\n","    print(\"Successfully imputed all null values.\")\n","else:\n","    print(f\"Warning: {null_count_after} null values remain. Global mode might not have been defined or some groups had no data.\")\n","\n","# Inspect some previously null rows\n","print(\"\\nExample rows that were previously null:\")\n","print(\n","    df_density_report\n","    .filter(pl.col('ProposedFoldingMethod').is_null())\n","    .select(['DateOfReport', 'GarmentType', 'ProposedLayout'])\n","    .head(10)\n","    .join(\n","        df_final_imputed.select(['DateOfReport', 'GarmentType', 'ProposedLayout', 'ProposedFoldingMethod']),\n","        on=['DateOfReport', 'GarmentType', 'ProposedLayout'], #\n","        how='left'\n","    )\n",")\n","\n","df_density_report = df_final_imputed"]},{"cell_type":"markdown","metadata":{"id":"HcJXOmt4h8OO"},"source":["The process of filling the missing `ProposedFoldingMethod` values is complete. The logic prioritized using the most specific contextual information available (combined group mode > garment type mode > global mode) to make the imputations as reasonable as possible.\n","\n","Now, we will erform a final check to confirm that all the missing values have indeed been filled!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMyvaMs6h8OP","outputId":"79dbbe76-cb3d-4914-8373-b2c040b3cb5c"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ReportID</th><th>ProductReference</th><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th><th>PackagingQuality</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"],"text/plain":["shape: (1, 11)\n","┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n","│ ReportID ┆ ProductRe ┆ DateOfRep ┆ SupplierN ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packaging │\n","│ ---      ┆ ference   ┆ ort       ┆ ame       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ Quality   │\n","│ u32      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---       │\n","│          ┆ u32       ┆ u32       ┆ u32       ┆   ┆ ---       ┆ ---       ┆ u32       ┆ u32       │\n","│          ┆           ┆           ┆           ┆   ┆ u32       ┆ u32       ┆           ┆           │\n","╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n","│ 0        ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n","└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["# do we have null values?\n","df_density_report.null_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZpMwd2Ch8OP","outputId":"c36e2673-a2f1-4462-ce4d-90f0d079345a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate rows found: 0\n"]}],"source":["# Do we have duplicate rows\n","num_duplicates = df_density_report.is_duplicated().sum()\n","print(f\"Number of duplicate rows found: {num_duplicates}\")"]},{"cell_type":"markdown","metadata":{"id":"YhN_txduh8OQ"},"source":["### Time of the day"]},{"cell_type":"markdown","metadata":{"id":"qT7IkGh7h8OQ"},"source":["Looking at the data we saw that `DateOfReport` seemed to have only the hours 00:00:00, we will find out if thats the case. If that happens across the dataset, we will remove it because of redundancy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rdZAcFyh8OR","outputId":"4c818637-bfc1-4478-9864-14f235dec6e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking for non-midnight times in Datetime column...\n","Has non-midnight times (using time object): False\n"]}],"source":["# we will check if we have different hours than midnight for DateOfReport or if everything is at midnight\n","from datetime import time\n","\n","# Check the current data type of the column\n","current_dtype = df_density_report['DateOfReport'].dtype\n","\n","if current_dtype == pl.Date:\n","    print(\"The 'DateOfReport' column is already of type Date. Time component has been removed.\")\n","    has_non_midnight = False\n","elif current_dtype == pl.Datetime:\n","    print(\"Checking for non-midnight times in Datetime column...\")\n","    has_non_midnight = df_density_report.select(\n","        (pl.col('DateOfReport').dt.time() != time(0, 0, 0)).any()\n","    ).item()\n","    print(f\"Has non-midnight times (using time object): {has_non_midnight}\")\n","else:\n","    print(f\"Unexpected data type for 'DateOfReport': {current_dtype}\")\n","    has_non_midnight = None"]},{"cell_type":"markdown","metadata":{"id":"Q2wVsBebh8OR"},"source":["Because we have the same hour for all of our entries(midnight) we will remove it and just leave the date"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utLSXi2uh8OT","outputId":"efe4c15f-62c8-4143-a10f-2f6d0f6a8b37"},"outputs":[{"name":"stdout","output_type":"stream","text":["All times are midnight. Converting 'DateOfReport' to Date type.\n","shape: (5, 11)\n","┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n","│ ReportID  ┆ ProductRe ┆ DateOfRep ┆ SupplierN ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packagin │\n","│ ---       ┆ ference   ┆ ort       ┆ ame       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ gQuality │\n","│ str       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---      │\n","│           ┆ str       ┆ date      ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ str      │\n","│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆           ┆          │\n","╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n","│ RPT000000 ┆ PRD07271  ┆ 2024-03-0 ┆ SupplierA ┆ … ┆ 29.0      ┆ Method2   ┆ LayoutC   ┆ Good     │\n","│ 1         ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD00861  ┆ 2024-05-2 ┆ SupplierC ┆ … ┆ 20.0      ┆ Method2   ┆ LayoutB   ┆ Good     │\n","│ 2         ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05391  ┆ 2023-11-1 ┆ SupplierA ┆ … ┆ 31.0      ┆ Method1   ┆ LayoutA   ┆ Good     │\n","│ 3         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05192  ┆ 2024-06-1 ┆ SupplierA ┆ … ┆ 5.0       ┆ Method1   ┆ LayoutD   ┆ Good     │\n","│ 4         ┆           ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05735  ┆ 2023-07-1 ┆ SupplierA ┆ … ┆ 9.0       ┆ Method2   ┆ LayoutD   ┆ Good     │\n","│ 5         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"]}],"source":["if not has_non_midnight:\n","    print(\"All times are midnight. Converting 'DateOfReport' to Date type.\")\n","    df_density_report = df_density_report.with_columns(\n","        pl.col('DateOfReport').cast(pl.Date)\n","    )\n","    # Verify the change\n","    print (df_density_report.head())\n","else:\n","    print(\"Non-midnight times found. Keeping 'DateOfReport' as Datetime.\")"]},{"cell_type":"markdown","metadata":{"id":"cx1aBvslh8OU"},"source":["### Numerical values"]},{"cell_type":"markdown","metadata":{"id":"TqVQiclCh8OU"},"source":["We will check if theres some strange values in the numerical columns: `Weight` and `ProposedUnitsPerCarton`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hv7w6ofdh8OU","outputId":"c685d63a-3254-4551-bd89-9b24ce1bc7f4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>statistic</th>\n","      <td>count</td>\n","      <td>null_count</td>\n","      <td>mean</td>\n","      <td>std</td>\n","      <td>min</td>\n","      <td>25%</td>\n","      <td>50%</td>\n","      <td>75%</td>\n","      <td>max</td>\n","    </tr>\n","    <tr>\n","      <th>Weight</th>\n","      <td>500000.0</td>\n","      <td>0.0</td>\n","      <td>0.461021</td>\n","      <td>0.349694</td>\n","      <td>0.08</td>\n","      <td>0.21</td>\n","      <td>0.33</td>\n","      <td>0.62</td>\n","      <td>2.32</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  0           1         2         3     4     5     6     7  \\\n","statistic     count  null_count      mean       std   min   25%   50%   75%   \n","Weight     500000.0         0.0  0.461021  0.349694  0.08  0.21  0.33  0.62   \n","\n","              8  \n","statistic   max  \n","Weight     2.32  "]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["# check value distribution for Weight\n","df_density_report.select(\n","    pl.col('Weight')\n",").describe().to_pandas().T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9lj11och8OW","outputId":"3b013831-ad33-4b22-ca44-78bcf26633a4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>statistic</th>\n","      <td>count</td>\n","      <td>null_count</td>\n","      <td>mean</td>\n","      <td>std</td>\n","      <td>min</td>\n","      <td>25%</td>\n","      <td>50%</td>\n","      <td>75%</td>\n","      <td>max</td>\n","    </tr>\n","    <tr>\n","      <th>ProposedUnitsPerCarton</th>\n","      <td>500000.0</td>\n","      <td>0.0</td>\n","      <td>99.981055</td>\n","      <td>864.741016</td>\n","      <td>-3.0</td>\n","      <td>16.0</td>\n","      <td>25.0</td>\n","      <td>32.0</td>\n","      <td>9999.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               0           1          2           3    4  \\\n","statistic                  count  null_count       mean         std  min   \n","ProposedUnitsPerCarton  500000.0         0.0  99.981055  864.741016 -3.0   \n","\n","                           5     6     7       8  \n","statistic                25%   50%   75%     max  \n","ProposedUnitsPerCarton  16.0  25.0  32.0  9999.0  "]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["# check value distribution for Weight\n","df_density_report.select(\n","    pl.col('ProposedUnitsPerCarton')\n",").describe().to_pandas().T"]},{"cell_type":"markdown","metadata":{"id":"Eqa7Xc2Jh8O3"},"source":["We can see two very noticeable things in `ProposedUnitsPerCarton`. First, we have negative values, which should be impossible and also a maximum value of 9999. We need to clean this situation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TV1uDRyQh8O4","outputId":"b67d902c-dfee-4d15-cfc1-9859b3e422f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows with ProposedUnitsPerCarton == 9999.0: 3786\n"]}],"source":["count_9999 = df_density_report.filter(pl.col('ProposedUnitsPerCarton') == 9999.0).height\n","print(f\"Number of rows with ProposedUnitsPerCarton == 9999.0: {count_9999}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjYUEvEEh8O4","outputId":"a5df64c1-9246-45e6-e55a-49f59a185c15"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of negative values in ProposedUnitsPerCarton: 3754\n","Unique negative values found:\n","shape: (1,)\n","Series: 'ProposedUnitsPerCarton' [f64]\n","[\n","\t-3.0\n","]\n"]}],"source":["#check how many negative values we have in proposed units per carton(count)\n","negative_count = df_density_report.filter(pl.col('ProposedUnitsPerCarton') < 0).height\n","print(f\"Number of negative values in ProposedUnitsPerCarton: {negative_count}\")\n","\n","# See the unique negative values\n","negative_values = df_density_report.filter(\n","    pl.col('ProposedUnitsPerCarton') < 0\n",")['ProposedUnitsPerCarton'].unique().sort()\n","\n","print(\"Unique negative values found:\")\n","print(negative_values)\n"]},{"cell_type":"markdown","metadata":{"id":"I6jhhDJWh8O5"},"source":["We have **3754** negative values, about **0.75%** of 500,000 rows. `9999.0` occurred **3,786** times (approx. **0.76%**). The thing is, Both `-3.0` and `9999.0` seem to be codes or sentinel values indicating missing, unavailable or erroneous data, rather than actual quantities. We will replace all occurrences of *both* `-3.0` and `9999.0` with `None` (null)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Nb2oUsdh8O5","outputId":"676d386a-e9fc-42cb-e4ca-d64d4608b59a"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Null count before cleaning codes: 0\n","- Min value before cleaning codes: -3.0\n","- Max value before cleaning codes: 9999.0\n","\n","Verifying replacement:\n","- Null count in ProposedUnitsPerCarton AFTER cleaning: 7540\n","  >> Confirmation: Null count increased by 7540 as expected.\n","- Minimum value in ProposedUnitsPerCarton after cleaning: 0.0\n","- Maximum value in ProposedUnitsPerCarton after cleaning: 49.0\n","- Remaining count of -3.0: 0\n","- Remaining count of 9999.0: 0\n","  >> Confirmation: Invalid codes successfully removed.\n"]}],"source":["original_null_count = df_density_report['ProposedUnitsPerCarton'].is_null().sum()\n","original_min = df_density_report['ProposedUnitsPerCarton'].min()\n","original_max = df_density_report['ProposedUnitsPerCarton'].max()\n","print(f\"- Null count before cleaning codes: {original_null_count}\")\n","print(f\"- Min value before cleaning codes: {original_min}\")\n","print(f\"- Max value before cleaning codes: {original_max}\")\n","\n","# Define the list of invalid code values to replace\n","invalid_codes = [-3.0, 9999.0]\n","num_negatives_to_replace = 3754 # Count of -3.0\n","num_9999_to_replace = 3786    # Count of 9999.0\n","total_expected_increase = num_negatives_to_replace + num_9999_to_replace\n","\n","# Replace both specific invalid codes with null using .is_in()\n","df_density_report = df_density_report.with_columns(\n","    pl.when(pl.col('ProposedUnitsPerCarton').is_in(invalid_codes))\n","    .then(None)\n","    .otherwise(pl.col('ProposedUnitsPerCarton'))\n","    .alias('ProposedUnitsPerCarton') )\n","\n","# Verification\n","# 1. Check the new null count (should have increased by total_expected_increase)\n","null_count_after = df_density_report['ProposedUnitsPerCarton'].is_null().sum()\n","print(\"\\nVerifying replacement:\")\n","print(f\"- Null count in ProposedUnitsPerCarton AFTER cleaning: {null_count_after}\")\n","if null_count_after == original_null_count + total_expected_increase:\n","    print(f\"  >> Confirmation: Null count increased by {total_expected_increase} as expected.\")\n","else:\n","    print(f\"  >> Warning: Null count change ({null_count_after - original_null_count}) doesn't match expected ({total_expected_increase}). Please review.\")\n","\n","# 2. Check the minimum value (should no longer be negative)\n","min_after_cleaning = df_density_report['ProposedUnitsPerCarton'].min()\n","print(f\"- Minimum value in ProposedUnitsPerCarton after cleaning: {min_after_cleaning}\")\n","\n","# 3. Check the maximum value (should no longer be 9999.0)\n","max_after_cleaning = df_density_report['ProposedUnitsPerCarton'].max()\n","print(f\"- Maximum value in ProposedUnitsPerCarton after cleaning: {max_after_cleaning}\")\n","\n","# 4. Check if the specific codes remain (should be none)\n","remaining_negatives = df_density_report.filter(pl.col('ProposedUnitsPerCarton') == -3.0).height\n","remaining_9999 = df_density_report.filter(pl.col('ProposedUnitsPerCarton') == 9999.0).height\n","print(f\"- Remaining count of -3.0: {remaining_negatives}\")\n","print(f\"- Remaining count of 9999.0: {remaining_9999}\")\n","if remaining_negatives == 0 and remaining_9999 == 0:\n","     print(\"  >> Confirmation: Invalid codes successfully removed.\")\n","else:\n","     print(\"  >> Warning: Some invalid code values still detected.\")"]},{"cell_type":"markdown","metadata":{"id":"qBRK-7VWh8O6"},"source":["Now we have **7,540** null values, aprox **1.5%** of the data. We will follow a similar approach to inpute the nulls like we did before, finding the median for each garment type."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKGVP2tAh8O7","outputId":"3c6152f3-9e28-4dd6-861b-7613cf3feaff"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Median Units per GarmentType (calculated from valid data) ---\n","shape: (12, 2)\n","┌─────────────┬─────────────────────┐\n","│ GarmentType ┆ MedianUnits_Garment │\n","│ ---         ┆ ---                 │\n","│ str         ┆ f64                 │\n","╞═════════════╪═════════════════════╡\n","│ Skirt       ┆ 27.0                │\n","│ Pants       ┆ 26.0                │\n","│ Suit        ┆ 11.0                │\n","│ Coat        ┆ 7.0                 │\n","│ Sweater     ┆ 15.0                │\n","│ …           ┆ …                   │\n","│ Shorts      ┆ 27.0                │\n","│ Hoodie      ┆ 13.0                │\n","│ Jacket      ┆ 14.0                │\n","│ Shirt       ┆ 33.0                │\n","│ Dress       ┆ 22.0                │\n","└─────────────┴─────────────────────┘\n","\n","Global valid median (for fallback): 25.0\n"]}],"source":["1. #Calculate median per GarmentType (filter out nulls first)\n","median_map_garment = (\n","    df_density_report.filter(pl.col('ProposedUnitsPerCarton').is_not_null()) # Use only non-null values for calculation\n","    .group_by('GarmentType')\n","    .agg(pl.median('ProposedUnitsPerCarton').alias('MedianUnits_Garment'))\n",")\n","print(\"\\n--- Median Units per GarmentType (calculated from valid data) ---\")\n","print(median_map_garment)\n","\n","# 2. Calculate global median from valid data\n","global_valid_median = df_density_report.filter(\n","    pl.col('ProposedUnitsPerCarton').is_not_null() # Use only non-null values\n",")['ProposedUnitsPerCarton'].median()\n","\n","print(f\"\\nGlobal valid median (for fallback): {global_valid_median}\")\n","\n","# Check if global median calculation was successful\n","if global_valid_median is None:\n","    print(\"Warning: Could not calculate global median. Imputation might fail.\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPXHeMvQh8O8","outputId":"e33f59dd-e2ff-4542-8303-e4808c52877f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Null count in ProposedUnitsPerCarton AFTER imputation: 0\n","Successfully imputed all null values.\n","Describe ProposedUnitsPerCarton after imputation\n","shape: (9, 2)\n","┌────────────┬────────────────────────┐\n","│ statistic  ┆ ProposedUnitsPerCarton │\n","│ ---        ┆ ---                    │\n","│ str        ┆ f64                    │\n","╞════════════╪════════════════════════╡\n","│ count      ┆ 500000.0               │\n","│ null_count ┆ 0.0                    │\n","│ mean       ┆ 24.663351              │\n","│ std        ┆ 11.1913                │\n","│ min        ┆ 0.0                    │\n","│ 25%        ┆ 16.0                   │\n","│ 50%        ┆ 25.0                   │\n","│ 75%        ┆ 32.0                   │\n","│ max        ┆ 49.0                   │\n","└────────────┴────────────────────────┘\n"]}],"source":["# 3. Join the calculated group medians back\n","df_impute_step = df_density_report.join(\n","    median_map_garment, on='GarmentType', how='left'\n",")\n","\n","# 4. Impute using coalesce (Original -> Group Median -> Global Median)\n","df_imputed = df_impute_step.with_columns(\n","    pl.coalesce(\n","        pl.col('ProposedUnitsPerCarton'),\n","        pl.col('MedianUnits_Garment'),\n","        pl.lit(global_valid_median)\n","    ).alias('ProposedUnitsPerCarton_Imputed')\n",")\n","\n","# 5. Clean up temporary column and overwrite original\n","df_final = df_imputed.drop(['MedianUnits_Garment'])\n","df_final = df_final.with_columns(\n","    pl.col('ProposedUnitsPerCarton_Imputed').alias('ProposedUnitsPerCarton')\n",").drop('ProposedUnitsPerCarton_Imputed')\n","\n","\n","# Verification\n","final_null_count = df_final['ProposedUnitsPerCarton'].is_null().sum()\n","print(f\"\\nNull count in ProposedUnitsPerCarton AFTER imputation: {final_null_count}\")\n","\n","if final_null_count == 0:\n","    print(\"Successfully imputed all null values.\")\n","    print(\"Describe ProposedUnitsPerCarton after imputation\")\n","    print(df_final.select(pl.col('ProposedUnitsPerCarton')).describe())\n","else:\n","    print(f\"Warning: {final_null_count} null values remain. Review median calculations and fallback.\")\n","\n","df_density_report = df_final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGGtKfEyh8O8","outputId":"f683f21a-bcb6-45d8-f9e4-7ac95e33698c"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (500_000, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ReportID</th><th>ProductReference</th><th>DateOfReport</th><th>SupplierName</th><th>GarmentType</th><th>Material</th><th>Weight</th><th>ProposedUnitsPerCarton</th><th>ProposedFoldingMethod</th><th>ProposedLayout</th><th>PackagingQuality</th></tr><tr><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;RPT0000001&quot;</td><td>&quot;PRD07271&quot;</td><td>2024-03-04</td><td>&quot;SupplierA&quot;</td><td>&quot;Pants&quot;</td><td>&quot;Polyester&quot;</td><td>0.35</td><td>29.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutC&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000002&quot;</td><td>&quot;PRD00861&quot;</td><td>2024-05-27</td><td>&quot;SupplierC&quot;</td><td>&quot;T-Shirt&quot;</td><td>&quot;Denim&quot;</td><td>0.21</td><td>20.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutB&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000003&quot;</td><td>&quot;PRD05391&quot;</td><td>2023-11-18</td><td>&quot;SupplierA&quot;</td><td>&quot;Shirt&quot;</td><td>&quot;Cotton&quot;</td><td>0.2</td><td>31.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutA&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000004&quot;</td><td>&quot;PRD05192&quot;</td><td>2024-06-13</td><td>&quot;SupplierA&quot;</td><td>&quot;Coat&quot;</td><td>&quot;Cotton&quot;</td><td>1.3</td><td>5.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutD&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0000005&quot;</td><td>&quot;PRD05735&quot;</td><td>2023-07-18</td><td>&quot;SupplierA&quot;</td><td>&quot;Coat&quot;</td><td>&quot;Polyester&quot;</td><td>1.11</td><td>9.0</td><td>&quot;Method2&quot;</td><td>&quot;LayoutD&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;RPT0499996&quot;</td><td>&quot;PRD06239&quot;</td><td>2023-03-26</td><td>&quot;SupplierB&quot;</td><td>&quot;T-Shirt&quot;</td><td>&quot;Polyester&quot;</td><td>0.13</td><td>43.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutB&quot;</td><td>&quot;Bad&quot;</td></tr><tr><td>&quot;RPT0499997&quot;</td><td>&quot;PRD02248&quot;</td><td>2023-11-16</td><td>&quot;SupplierB&quot;</td><td>&quot;T-Shirt&quot;</td><td>&quot;Cotton&quot;</td><td>0.14</td><td>37.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutA&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0499998&quot;</td><td>&quot;PRD07434&quot;</td><td>2024-05-17</td><td>&quot;SupplierE&quot;</td><td>&quot;Pants&quot;</td><td>&quot;Cotton&quot;</td><td>0.42</td><td>12.5</td><td>&quot;Method1&quot;</td><td>&quot;LayoutB&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0499999&quot;</td><td>&quot;PRD04320&quot;</td><td>2024-01-11</td><td>&quot;SupplierB&quot;</td><td>&quot;Dress&quot;</td><td>&quot;Cotton&quot;</td><td>0.51</td><td>19.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutB&quot;</td><td>&quot;Good&quot;</td></tr><tr><td>&quot;RPT0500000&quot;</td><td>&quot;PRD06196&quot;</td><td>2023-09-05</td><td>&quot;SupplierC&quot;</td><td>&quot;Shirt&quot;</td><td>&quot;Polyester&quot;</td><td>0.14</td><td>44.0</td><td>&quot;Method1&quot;</td><td>&quot;LayoutA&quot;</td><td>&quot;Good&quot;</td></tr></tbody></table></div>"],"text/plain":["shape: (500_000, 11)\n","┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n","│ ReportID  ┆ ProductRe ┆ DateOfRep ┆ SupplierN ┆ … ┆ ProposedU ┆ ProposedF ┆ ProposedL ┆ Packagin │\n","│ ---       ┆ ference   ┆ ort       ┆ ame       ┆   ┆ nitsPerCa ┆ oldingMet ┆ ayout     ┆ gQuality │\n","│ str       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ rton      ┆ hod       ┆ ---       ┆ ---      │\n","│           ┆ str       ┆ date      ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ str      │\n","│           ┆           ┆           ┆           ┆   ┆ f64       ┆ str       ┆           ┆          │\n","╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n","│ RPT000000 ┆ PRD07271  ┆ 2024-03-0 ┆ SupplierA ┆ … ┆ 29.0      ┆ Method2   ┆ LayoutC   ┆ Good     │\n","│ 1         ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD00861  ┆ 2024-05-2 ┆ SupplierC ┆ … ┆ 20.0      ┆ Method2   ┆ LayoutB   ┆ Good     │\n","│ 2         ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05391  ┆ 2023-11-1 ┆ SupplierA ┆ … ┆ 31.0      ┆ Method1   ┆ LayoutA   ┆ Good     │\n","│ 3         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05192  ┆ 2024-06-1 ┆ SupplierA ┆ … ┆ 5.0       ┆ Method1   ┆ LayoutD   ┆ Good     │\n","│ 4         ┆           ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT000000 ┆ PRD05735  ┆ 2023-07-1 ┆ SupplierA ┆ … ┆ 9.0       ┆ Method2   ┆ LayoutD   ┆ Good     │\n","│ 5         ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n","│ RPT049999 ┆ PRD06239  ┆ 2023-03-2 ┆ SupplierB ┆ … ┆ 43.0      ┆ Method1   ┆ LayoutB   ┆ Bad      │\n","│ 6         ┆           ┆ 6         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT049999 ┆ PRD02248  ┆ 2023-11-1 ┆ SupplierB ┆ … ┆ 37.0      ┆ Method1   ┆ LayoutA   ┆ Good     │\n","│ 7         ┆           ┆ 6         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT049999 ┆ PRD07434  ┆ 2024-05-1 ┆ SupplierE ┆ … ┆ 12.5      ┆ Method1   ┆ LayoutB   ┆ Good     │\n","│ 8         ┆           ┆ 7         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT049999 ┆ PRD04320  ┆ 2024-01-1 ┆ SupplierB ┆ … ┆ 19.0      ┆ Method1   ┆ LayoutB   ┆ Good     │\n","│ 9         ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n","│ RPT050000 ┆ PRD06196  ┆ 2023-09-0 ┆ SupplierC ┆ … ┆ 44.0      ┆ Method1   ┆ LayoutA   ┆ Good     │\n","│ 0         ┆           ┆ 5         ┆           ┆   ┆           ┆           ┆           ┆          │\n","└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"]},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["df_density_report"]},{"cell_type":"markdown","metadata":{"id":"KRpdR0Q0h8O9"},"source":["### Uncertain in `PackagingQuality`"]},{"cell_type":"markdown","metadata":{"id":"4Ebb6zrgh8O9"},"source":["In the instructions we have this: PackagingQuality: Operational label indicating the packaging quality (\"Good\" or \"Bad\"),\n","based on predefined criteria. We shouldnt have `Uncertain` as an option, so we need to analyze this"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXq5av64h8O9","outputId":"ac1cb8f2-6c4c-448e-8cfd-b09967101f93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total uncertain values in PackagingQuality: 1863\n","Date statistics for 'Uncertain' PackagingQuality\n","Minimum Date: 2023-01-01\n","Maximum Date: 2024-06-30\n","Number of unique dates: 526\n","Overall Date Range in df_density_report\n","Minimum Date: 2023-01-01\n","Maximum Date: 2024-06-30\n","Total Date Range Span: 546 days, 0:00:00\n"]}],"source":["# how many uncertain values with 'Uncertain' are there in PackagingQuality\n","uncertain_count = df_density_report.filter(pl.col('PackagingQuality') == 'Uncertain').shape[0]\n","print(f\"Total uncertain values in PackagingQuality: {uncertain_count}\")\n","\n","#lets check if they are recent or have older dates\n","# Ensure 'DateOfReport' is of Date type if it's not already (it should be from cell 35)\n","if df_density_report['DateOfReport'].dtype != pl.Date:\n","     df_density_report = df_density_report.with_columns(\n","         pl.col('DateOfReport').cast(pl.Date)\n","     )\n","\n","# Filter for 'Uncertain' quality and check date distribution\n","uncertain_dates = df_density_report.filter(pl.col('PackagingQuality') == 'Uncertain')['DateOfReport']\n","\n","print(f\"Date statistics for 'Uncertain' PackagingQuality\")\n","if uncertain_dates.len() > 0:\n","    print(f\"Minimum Date: {uncertain_dates.min()}\")\n","    print(f\"Maximum Date: {uncertain_dates.max()}\")\n","    print(f\"Number of unique dates: {uncertain_dates.n_unique()}\")\n","    # You can add more analysis like plotting the distribution if needed\n","    # Example: uncertain_dates.value_counts().sort('DateOfReport').head()\n","else:\n","    print(\"No rows found with 'Uncertain' PackagingQuality.\")\n","\n","\n","# Check the overall date range in the dataframe\n","min_date = df_density_report['DateOfReport'].min()\n","max_date = df_density_report['DateOfReport'].max()\n","print(f\"Overall Date Range in df_density_report\")\n","print(f\"Minimum Date: {min_date}\")\n","print(f\"Maximum Date: {max_date}\")\n","if min_date is not None and max_date is not None:\n","    date_range = max_date - min_date\n","    print(f\"Total Date Range Span: {date_range}\")\n","else:\n","     print(\"Could not calculate date range (min or max date is null).\")\n"]},{"cell_type":"markdown","metadata":{"id":"lKYoqyDIh8O_"},"source":["The dates are not an issue, its not the more recent packages that are `Uncertain`. Because of the importance of the column, we will leave them as  `null` for now."]},{"cell_type":"markdown","metadata":{"id":"IjEfI6mnUI5_"},"source":["## 2. Historical Incidents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckTJgzGzUOiZ"},"outputs":[],"source":["# Read excel file of historical incidents\n","df_historical_incidents = pl.from_pandas(pd.read_excel(PATH_HISTORICAL_INCIDENTS))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q85_vT6Qh8PR","outputId":"b11f37b1-1df5-4d05-a501-be8c63c4ced5"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ProductReference</th><th>SupplierName</th><th>DateOfIncident</th><th>IssueDescription</th><th>ResolutionStatus</th><th>CostImpact (€)</th></tr><tr><td>str</td><td>str</td><td>datetime[ns]</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;PRD08586&quot;</td><td>&quot;SupplierC&quot;</td><td>2023-10-25 00:00:00</td><td>&quot;Other&quot;</td><td>&quot;Resolved&quot;</td><td>69.0</td></tr><tr><td>&quot;PRD06004&quot;</td><td>&quot;SupplierA&quot;</td><td>2024-03-07 00:00:00</td><td>&quot;Packaging Damage&quot;</td><td>&quot;Resolved&quot;</td><td>1912.0</td></tr><tr><td>&quot;PRD04841&quot;</td><td>&quot;SupplierC&quot;</td><td>2023-01-19 00:00:00</td><td>&quot;Missing Items&quot;</td><td>&quot;Resolved&quot;</td><td>379.0</td></tr><tr><td>&quot;PRD02036&quot;</td><td>&quot;SupplierC&quot;</td><td>2024-05-28 00:00:00</td><td>&quot;Other&quot;</td><td>&quot;In Progress&quot;</td><td>327.0</td></tr><tr><td>&quot;PRD02537&quot;</td><td>&quot;SupplierE&quot;</td><td>2023-08-11 00:00:00</td><td>&quot;Incorrect Folding&quot;</td><td>&quot;Not Resolved&quot;</td><td>560.0</td></tr></tbody></table></div>"],"text/plain":["shape: (5, 6)\n","┌─────────────────┬──────────────┬─────────────────┬─────────────────┬────────────────┬────────────┐\n","│ ProductReferenc ┆ SupplierName ┆ DateOfIncident  ┆ IssueDescriptio ┆ ResolutionStat ┆ CostImpact │\n","│ e               ┆ ---          ┆ ---             ┆ n               ┆ us             ┆ (€)        │\n","│ ---             ┆ str          ┆ datetime[ns]    ┆ ---             ┆ ---            ┆ ---        │\n","│ str             ┆              ┆                 ┆ str             ┆ str            ┆ f64        │\n","╞═════════════════╪══════════════╪═════════════════╪═════════════════╪════════════════╪════════════╡\n","│ PRD08586        ┆ SupplierC    ┆ 2023-10-25      ┆ Other           ┆ Resolved       ┆ 69.0       │\n","│                 ┆              ┆ 00:00:00        ┆                 ┆                ┆            │\n","│ PRD06004        ┆ SupplierA    ┆ 2024-03-07      ┆ Packaging       ┆ Resolved       ┆ 1912.0     │\n","│                 ┆              ┆ 00:00:00        ┆ Damage          ┆                ┆            │\n","│ PRD04841        ┆ SupplierC    ┆ 2023-01-19      ┆ Missing Items   ┆ Resolved       ┆ 379.0      │\n","│                 ┆              ┆ 00:00:00        ┆                 ┆                ┆            │\n","│ PRD02036        ┆ SupplierC    ┆ 2024-05-28      ┆ Other           ┆ In Progress    ┆ 327.0      │\n","│                 ┆              ┆ 00:00:00        ┆                 ┆                ┆            │\n","│ PRD02537        ┆ SupplierE    ┆ 2023-08-11      ┆ Incorrect       ┆ Not Resolved   ┆ 560.0      │\n","│                 ┆              ┆ 00:00:00        ┆ Folding         ┆                ┆            │\n","└─────────────────┴──────────────┴─────────────────┴─────────────────┴────────────────┴────────────┘"]},"execution_count":193,"metadata":{},"output_type":"execute_result"}],"source":["df_historical_incidents.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwE_ws7Bh8PR","outputId":"7e25cfe4-ec84-4795-de36-c2ebbbcd3394"},"outputs":[{"data":{"text/plain":["Schema([('ReportID', String),\n","        ('ProductReference', String),\n","        ('DateOfReport', Date),\n","        ('SupplierName', String),\n","        ('GarmentType', String),\n","        ('Material', String),\n","        ('Weight', Float64),\n","        ('ProposedUnitsPerCarton', Float64),\n","        ('ProposedFoldingMethod', String),\n","        ('ProposedLayout', String),\n","        ('PackagingQuality', String)])"]},"execution_count":194,"metadata":{},"output_type":"execute_result"}],"source":["# now we will see the structure of the file\n","df_density_report.schema"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8E8sxn5rh8PS","outputId":"09ae093e-1f0d-4c78-9273-a6014c0f95fb"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ProductReference</th><th>SupplierName</th><th>DateOfIncident</th><th>IssueDescription</th><th>ResolutionStatus</th><th>CostImpact (€)</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"],"text/plain":["shape: (1, 6)\n","┌─────────────────┬──────────────┬─────────────────┬─────────────────┬────────────────┬────────────┐\n","│ ProductReferenc ┆ SupplierName ┆ DateOfIncident  ┆ IssueDescriptio ┆ ResolutionStat ┆ CostImpact │\n","│ e               ┆ ---          ┆ ---             ┆ n               ┆ us             ┆ (€)        │\n","│ ---             ┆ u32          ┆ u32             ┆ ---             ┆ ---            ┆ ---        │\n","│ u32             ┆              ┆                 ┆ u32             ┆ u32            ┆ u32        │\n","╞═════════════════╪══════════════╪═════════════════╪═════════════════╪════════════════╪════════════╡\n","│ 0               ┆ 0            ┆ 0               ┆ 0               ┆ 0              ┆ 0          │\n","└─────────────────┴──────────────┴─────────────────┴─────────────────┴────────────────┴────────────┘"]},"execution_count":195,"metadata":{},"output_type":"execute_result"}],"source":["# do we have null values?\n","df_historical_incidents.null_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eZw5pbVh8PU","outputId":"3329d892-bded-4268-b38f-a63b2c7272e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate rows found: 0\n"]}],"source":["# do we have repeated values?\n","num_duplicates = df_historical_incidents.is_duplicated().sum()\n","print(f\"Number of duplicate rows found: {num_duplicates}\")"]},{"cell_type":"markdown","metadata":{"id":"-1DjgDh3h8PW"},"source":["We dont have nulls or duplicates, we will repeat the same process as before. We will start with the hour in `DateOfIncident`."]},{"cell_type":"markdown","metadata":{"id":"GaX_rxM_h8PX"},"source":["### Time of the day"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ic8mgKqYh8PX","outputId":"178a1dfc-23d1-4652-f677-c2071ad7e31b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Does 'DateOfIncident' have non-midnight times? False\n","All times are midnight.\n","New dtype of DateOfIncident: Date\n"]}],"source":["# Check if any non-midnight times exist\n","has_non_midnight_incident = df_historical_incidents.select(\n","    (pl.col('DateOfIncident').dt.time() != time(0, 0, 0)).any()\n",").item()\n","\n","print(f\"Does 'DateOfIncident' have non-midnight times? {has_non_midnight_incident}\")\n","\n","if not has_non_midnight_incident:\n","    print(\"All times are midnight.\")\n","    # Corrected line: Use df_historical_incidents instead of x\n","    df_historical_incidents = df_historical_incidents.with_columns(\n","        pl.col('DateOfIncident').cast(pl.Date)\n","    )\n","    # Optional: Verify the change\n","    print(f\"New dtype of DateOfIncident: {df_historical_incidents['DateOfIncident'].dtype}\")\n","else:\n","    print(\"Non-midnight times found. Keeping 'DateOfIncident' as Datetime.\")"]},{"cell_type":"markdown","metadata":{"id":"851jFtBdh8PY"},"source":["### Naming consistency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aje5zwz5h8PZ","outputId":"78a34884-9690-4ea4-d21e-927215bcd183"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking Unique Values for Potential Inconsistencies in Historical Incidents\n","Unique values in: SupplierName\n","['SPLF', 'SuplA', 'SupllierC', 'SuppB', 'SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH', 'supplierA', 'supplierh']\n","Total unique non-null values: 14\n","Unique values in: IssueDescription\n","['Incorrect Folding', 'Labeling Error', 'Missing Items', 'Other', 'Packaging Damage', 'Product Wrinkled', 'Transportation Damage']\n","Total unique non-null values: 7\n","Unique values in: ResolutionStatus\n","['In Progress', 'Not Resolved', 'Resolved']\n","Total unique non-null values: 3\n"]}],"source":["columns_to_check = [\n","    'SupplierName',\n","    'IssueDescription',\n","    'ResolutionStatus']\n","\n","print(\"Checking Unique Values for Potential Inconsistencies in Historical Incidents\")\n","\n","for col_name in columns_to_check:\n","    if col_name in df_historical_incidents.columns:\n","        try:\n","            unique_values = (\n","                df_historical_incidents[col_name]\n","                .unique()\n","                .sort()\n","            )\n","\n","            print(f\"Unique values in: {col_name}\")\n","            print(unique_values.to_list())\n","            print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")\n","\n","        except Exception as e:\n","            print(f\"Could not process column: {col_name}\")\n","            print(f\"Error: {e}\")\n","    else:\n","        print(f\"Column not found: {col_name}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6LbKgnqVh8Pb"},"source":["Good, we only have wrong names in `SupplierName`, we will do the same as with the first dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQyKNI6Oh8Pb","outputId":"55a057af-0063-415b-8d30-432bdb1d5b5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values in: SupplierName\n","['SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH']\n","Total unique non-null values: 8\n"]}],"source":["#fixing SupplierName\n","supplier_mapping_hi = {\n","    'SuplA': 'SupplierA',\n","    'supplierA': 'SupplierA',\n","    'SuppB': 'SupplierB',\n","    'SupllierC': 'SupplierC',\n","    'SPLF': 'SupplierF',\n","    'supplierh': 'SupplierH',\n","}\n","\n","# Apply the mapping\n","df_historical_incidents = df_historical_incidents.with_columns(\n","    pl.col('SupplierName')\n","      .str.strip_chars()\n","      .replace(supplier_mapping_hi)\n","      .str.replace_all(\" \", \"\")\n","      .alias('SupplierName')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_historical_incidents['SupplierName']\n","    .unique()\n","    .sort()\n",")\n","print(f\"Unique values in: SupplierName\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lip4WBTVh8Pc","outputId":"11cef447-66c1-407a-bc51-e26d5967c80e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Checking statistics for 'CostImpact (€)':\n","shape: (9, 2)\n","┌────────────┬────────────────┐\n","│ statistic  ┆ CostImpact (€) │\n","│ ---        ┆ ---            │\n","│ str        ┆ f64            │\n","╞════════════╪════════════════╡\n","│ count      ┆ 18000.0        │\n","│ null_count ┆ 0.0            │\n","│ mean       ┆ 555.215833     │\n","│ std        ┆ 492.948178     │\n","│ min        ┆ 50.0           │\n","│ 25%        ┆ 224.0          │\n","│ 50%        ┆ 365.0          │\n","│ 75%        ┆ 693.75         │\n","│ max        ┆ 2500.0         │\n","└────────────┴────────────────┘\n","\n","Minimum CostImpact (€): 50.0\n"]}],"source":["print(\"\\nChecking statistics for 'CostImpact (€)':\")\n","# Handle potential column name issues if the ' (€)' causes problems later, but describe should work.\n","try:\n","    cost_stats = df_historical_incidents.select(pl.col('CostImpact (€)')).describe()\n","    print(cost_stats) # .to_pandas().T might be easier to read if preferred\n","\n","    # Specifically check min value\n","    min_cost = df_historical_incidents['CostImpact (€)'].min()\n","    print(f\"\\nMinimum CostImpact (€): {min_cost}\")\n","    if min_cost is not None and min_cost < 0:\n","         print(\"Warning: Negative CostImpact found!\")\n","\n","except Exception as e:\n","    print(f\"Error describing 'CostImpact (€)': {e}\")\n","    print(\"Check if the column name is exactly 'CostImpact (€)'\")"]},{"cell_type":"markdown","metadata":{"id":"T4vmAYqoVHzI"},"source":["## 3. Product Attributes"]},{"cell_type":"markdown","metadata":{"id":"WBaiu_s6Wk7w"},"source":["There is no need to clean this dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcViNNZ6ViKF"},"outputs":[],"source":["# Read excel file of product attributes\n","df_product_attributes = pl.from_pandas(pd.read_excel(PATH_PRODUCT_ATTRIBUTES))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWR0ofNvh8Pe","outputId":"83d8e2d3-2c8d-4328-e90f-59b3ff7fc2ee"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ProductReference</th><th>ProductName</th><th>GarmentType</th><th>Material</th><th>Size</th><th>Collection</th><th>Weight</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;PRD00001&quot;</td><td>&quot;Jacket Cotton L&quot;</td><td>&quot;Jacket&quot;</td><td>&quot;Cotton&quot;</td><td>&quot;L&quot;</td><td>&quot;Summer&quot;</td><td>0.84</td></tr><tr><td>&quot;PRD00002&quot;</td><td>&quot;Shorts Cotton S&quot;</td><td>&quot;Shorts&quot;</td><td>&quot;Cotton&quot;</td><td>&quot;S&quot;</td><td>&quot;Summer&quot;</td><td>0.35</td></tr><tr><td>&quot;PRD00003&quot;</td><td>&quot;Sweater Cotton M&quot;</td><td>&quot;Sweater&quot;</td><td>&quot;Cotton&quot;</td><td>&quot;M&quot;</td><td>&quot;Spring&quot;</td><td>0.85</td></tr><tr><td>&quot;PRD00004&quot;</td><td>&quot;Skirt Polyester L&quot;</td><td>&quot;Skirt&quot;</td><td>&quot;Polyester&quot;</td><td>&quot;L&quot;</td><td>&quot;Winter&quot;</td><td>0.25</td></tr><tr><td>&quot;PRD00005&quot;</td><td>&quot;Shirt Polyester M&quot;</td><td>&quot;Shirt&quot;</td><td>&quot;Polyester&quot;</td><td>&quot;M&quot;</td><td>&quot;Spring&quot;</td><td>0.16</td></tr></tbody></table></div>"],"text/plain":["shape: (5, 7)\n","┌──────────────────┬───────────────────┬─────────────┬───────────┬──────┬────────────┬────────┐\n","│ ProductReference ┆ ProductName       ┆ GarmentType ┆ Material  ┆ Size ┆ Collection ┆ Weight │\n","│ ---              ┆ ---               ┆ ---         ┆ ---       ┆ ---  ┆ ---        ┆ ---    │\n","│ str              ┆ str               ┆ str         ┆ str       ┆ str  ┆ str        ┆ f64    │\n","╞══════════════════╪═══════════════════╪═════════════╪═══════════╪══════╪════════════╪════════╡\n","│ PRD00001         ┆ Jacket Cotton L   ┆ Jacket      ┆ Cotton    ┆ L    ┆ Summer     ┆ 0.84   │\n","│ PRD00002         ┆ Shorts Cotton S   ┆ Shorts      ┆ Cotton    ┆ S    ┆ Summer     ┆ 0.35   │\n","│ PRD00003         ┆ Sweater Cotton M  ┆ Sweater     ┆ Cotton    ┆ M    ┆ Spring     ┆ 0.85   │\n","│ PRD00004         ┆ Skirt Polyester L ┆ Skirt       ┆ Polyester ┆ L    ┆ Winter     ┆ 0.25   │\n","│ PRD00005         ┆ Shirt Polyester M ┆ Shirt       ┆ Polyester ┆ M    ┆ Spring     ┆ 0.16   │\n","└──────────────────┴───────────────────┴─────────────┴───────────┴──────┴────────────┴────────┘"]},"execution_count":202,"metadata":{},"output_type":"execute_result"}],"source":["df_product_attributes.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJIR4uA8h8Pf","outputId":"6dce13bf-1d10-4ea5-f51d-9f74fec32c59"},"outputs":[{"data":{"text/plain":["Schema([('ProductReference', String),\n","        ('ProductName', String),\n","        ('GarmentType', String),\n","        ('Material', String),\n","        ('Size', String),\n","        ('Collection', String),\n","        ('Weight', Float64)])"]},"execution_count":203,"metadata":{},"output_type":"execute_result"}],"source":["# now we will see the structure of the file\n","df_product_attributes.schema"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mgwkE2yh8Pg","outputId":"6d415a15-dc0a-428f-a706-2d96155f5129"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate rows found: 0\n","Number of null values found: shape: (1, 7)\n","┌──────────────────┬─────────────┬─────────────┬──────────┬──────┬────────────┬────────┐\n","│ ProductReference ┆ ProductName ┆ GarmentType ┆ Material ┆ Size ┆ Collection ┆ Weight │\n","│ ---              ┆ ---         ┆ ---         ┆ ---      ┆ ---  ┆ ---        ┆ ---    │\n","│ u32              ┆ u32         ┆ u32         ┆ u32      ┆ u32  ┆ u32        ┆ u32    │\n","╞══════════════════╪═════════════╪═════════════╪══════════╪══════╪════════════╪════════╡\n","│ 0                ┆ 0           ┆ 0           ┆ 0        ┆ 0    ┆ 0          ┆ 0      │\n","└──────────────────┴─────────────┴─────────────┴──────────┴──────┴────────────┴────────┘\n"]}],"source":["# do we have duplicate rows\n","num_duplicates = df_product_attributes.is_duplicated().sum()\n","print(f\"Number of duplicate rows found: {num_duplicates}\")\n","# do we have null values?\n","num_nulls = df_product_attributes.null_count()\n","print(f\"Number of null values found: {num_nulls}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_TL-eZvh8Pg","outputId":"0ba2b663-10b0-40e7-8d7e-c0797e64859e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Is ProductReference unique across all rows? True\n"]}],"source":["# Check if ProductReference is unique\n","is_prod_ref_unique = df_product_attributes['ProductReference'].is_unique().all()\n","print(f\"Is ProductReference unique across all rows? {is_prod_ref_unique}\")\n","if not is_prod_ref_unique:\n","     non_unique_prod_refs = df_product_attributes.group_by('ProductReference').agg(pl.count()).filter(pl.col('count') > 1)\n","     print(f\"Number of non-unique ProductReferences: {non_unique_prod_refs.height}\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UffcIHn-h8Ph","outputId":"315c4b51-f0f1-4631-979a-078c15c4147f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking Unique Values for Potential Inconsistencies in Historical Incidents\n","Unique values in: GarmentType\n","['Blouse', 'Coat', 'Dress', 'Hoodie', 'Jacket', 'Pants', 'Shirt', 'Shorts', 'Skirt', 'Suit', 'Sweater', 'T-Shirt']\n","Total unique non-null values: 12\n","Unique values in: Material\n","['Cotton', 'Denim', 'Linen', 'Polyester', 'Silk', 'Wool']\n","Total unique non-null values: 6\n","Unique values in: Size\n","['L', 'M', 'S', 'XL', 'XS']\n","Total unique non-null values: 5\n","Unique values in: Collection\n","['Autumn', 'Spring', 'Summer', 'Winter']\n","Total unique non-null values: 4\n"]}],"source":["columns_to_check = [\n","    'GarmentType',\n","    'Material',\n","    'Size',\n","    'Collection']\n","\n","print(\"Checking Unique Values for Potential Inconsistencies in Historical Incidents\")\n","\n","for col_name in columns_to_check:\n","    if col_name in df_product_attributes.columns:\n","        try:\n","            unique_values = (\n","                df_product_attributes[col_name]\n","                .unique()\n","                .sort()\n","            )\n","\n","            print(f\"Unique values in: {col_name}\")\n","            print(unique_values.to_list())\n","            print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")\n","\n","        except Exception as e:\n","            print(f\"Could not process column: {col_name}\")\n","            print(f\"Error: {e}\")\n","    else:\n","        print(f\"Column not found: {col_name}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kNl3APC6WmW9"},"source":["## 4. Supplier Scorecard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dr_Z0fXhWvFe"},"outputs":[],"source":["# Read excel file of supplier scorecard\n","df_supplier_scorecard = pl.from_pandas(pd.read_excel(PATH_SUPPLIER_SCORECARD))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OlVfOILh8Pj","outputId":"3855f2e2-f627-4812-c18a-dba0a793d414"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SupplierName</th><th>Month</th><th>PackagesHandled</th><th>BadPackagingRate (%)</th><th>TotalIncidents</th><th>AverageCostPerIncident (€)</th><th>OnTimeDeliveryRate (%)</th><th>AnomaliesDetected</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;SupplierA&quot;</td><td>&quot;2023-01&quot;</td><td>7841</td><td>8.46</td><td>133</td><td>538.23</td><td>86.01</td><td>23</td></tr><tr><td>&quot;SupplierA&quot;</td><td>&quot;2023-02&quot;</td><td>7196</td><td>7.78</td><td>153</td><td>572.14</td><td>88.09</td><td>16</td></tr><tr><td>&quot;SupplierA&quot;</td><td>&quot;2023-03&quot;</td><td>7842</td><td>7.94</td><td>163</td><td>547.51</td><td>84.74</td><td>21</td></tr><tr><td>&quot;SupplierA&quot;</td><td>&quot;2023-04&quot;</td><td>7587</td><td>7.7</td><td>158</td><td>588.33</td><td>91.58</td><td>18</td></tr><tr><td>&quot;SupplierA&quot;</td><td>&quot;2023-05&quot;</td><td>8010</td><td>7.77</td><td>166</td><td>618.34</td><td>96.87</td><td>18</td></tr></tbody></table></div>"],"text/plain":["shape: (5, 8)\n","┌────────────┬─────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┐\n","│ SupplierNa ┆ Month   ┆ PackagesHa ┆ BadPackagi ┆ TotalIncid ┆ AverageCos ┆ OnTimeDel ┆ Anomalies │\n","│ me         ┆ ---     ┆ ndled      ┆ ngRate (%) ┆ ents       ┆ tPerIncide ┆ iveryRate ┆ Detected  │\n","│ ---        ┆ str     ┆ ---        ┆ ---        ┆ ---        ┆ nt (€)     ┆ (%)       ┆ ---       │\n","│ str        ┆         ┆ i64        ┆ f64        ┆ i64        ┆ ---        ┆ ---       ┆ i64       │\n","│            ┆         ┆            ┆            ┆            ┆ f64        ┆ f64       ┆           │\n","╞════════════╪═════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╡\n","│ SupplierA  ┆ 2023-01 ┆ 7841       ┆ 8.46       ┆ 133        ┆ 538.23     ┆ 86.01     ┆ 23        │\n","│ SupplierA  ┆ 2023-02 ┆ 7196       ┆ 7.78       ┆ 153        ┆ 572.14     ┆ 88.09     ┆ 16        │\n","│ SupplierA  ┆ 2023-03 ┆ 7842       ┆ 7.94       ┆ 163        ┆ 547.51     ┆ 84.74     ┆ 21        │\n","│ SupplierA  ┆ 2023-04 ┆ 7587       ┆ 7.7        ┆ 158        ┆ 588.33     ┆ 91.58     ┆ 18        │\n","│ SupplierA  ┆ 2023-05 ┆ 8010       ┆ 7.77       ┆ 166        ┆ 618.34     ┆ 96.87     ┆ 18        │\n","└────────────┴─────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┘"]},"execution_count":208,"metadata":{},"output_type":"execute_result"}],"source":["df_supplier_scorecard.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqZLkSbIh8Pl","outputId":"f56d0dce-e5af-4b5d-b7c8-a5a46bd20b2c"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (9, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>SupplierName</th><th>Month</th><th>PackagesHandled</th><th>BadPackagingRate (%)</th><th>TotalIncidents</th><th>AverageCostPerIncident (€)</th><th>OnTimeDeliveryRate (%)</th><th>AnomaliesDetected</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;252&quot;</td><td>&quot;252&quot;</td><td>252.0</td><td>252.0</td><td>252.0</td><td>252.0</td><td>252.0</td><td>252.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>1984.126984</td><td>23.04754</td><td>70.436508</td><td>552.654524</td><td>75.397857</td><td>11.698413</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>2382.57589</td><td>9.242888</td><td>71.666892</td><td>215.370064</td><td>8.923621</td><td>12.036644</td></tr><tr><td>&quot;min&quot;</td><td>&quot;SPLF&quot;</td><td>&quot;2023-01&quot;</td><td>66.0</td><td>7.29</td><td>0.0</td><td>0.0</td><td>60.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>95.0</td><td>16.67</td><td>3.0</td><td>484.78</td><td>68.88</td><td>1.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>1343.0</td><td>21.05</td><td>46.0</td><td>544.72</td><td>76.46</td><td>9.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>2957.0</td><td>27.46</td><td>149.0</td><td>611.59</td><td>81.84</td><td>20.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;supplierh&quot;</td><td>&quot;2024-06&quot;</td><td>8019.0</td><td>45.85</td><td>210.0</td><td>1969.0</td><td>96.87</td><td>43.0</td></tr></tbody></table></div>"],"text/plain":["shape: (9, 9)\n","┌────────────┬───────────┬─────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n","│ statistic  ┆ SupplierN ┆ Month   ┆ PackagesH ┆ … ┆ TotalInci ┆ AverageCo ┆ OnTimeDel ┆ Anomalies │\n","│ ---        ┆ ame       ┆ ---     ┆ andled    ┆   ┆ dents     ┆ stPerInci ┆ iveryRate ┆ Detected  │\n","│ str        ┆ ---       ┆ str     ┆ ---       ┆   ┆ ---       ┆ dent (€)  ┆ (%)       ┆ ---       │\n","│            ┆ str       ┆         ┆ f64       ┆   ┆ f64       ┆ ---       ┆ ---       ┆ f64       │\n","│            ┆           ┆         ┆           ┆   ┆           ┆ f64       ┆ f64       ┆           │\n","╞════════════╪═══════════╪═════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n","│ count      ┆ 252       ┆ 252     ┆ 252.0     ┆ … ┆ 252.0     ┆ 252.0     ┆ 252.0     ┆ 252.0     │\n","│ null_count ┆ 0         ┆ 0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n","│ mean       ┆ null      ┆ null    ┆ 1984.1269 ┆ … ┆ 70.436508 ┆ 552.65452 ┆ 75.397857 ┆ 11.698413 │\n","│            ┆           ┆         ┆ 84        ┆   ┆           ┆ 4         ┆           ┆           │\n","│ std        ┆ null      ┆ null    ┆ 2382.5758 ┆ … ┆ 71.666892 ┆ 215.37006 ┆ 8.923621  ┆ 12.036644 │\n","│            ┆           ┆         ┆ 9         ┆   ┆           ┆ 4         ┆           ┆           │\n","│ min        ┆ SPLF      ┆ 2023-01 ┆ 66.0      ┆ … ┆ 0.0       ┆ 0.0       ┆ 60.0      ┆ 0.0       │\n","│ 25%        ┆ null      ┆ null    ┆ 95.0      ┆ … ┆ 3.0       ┆ 484.78    ┆ 68.88     ┆ 1.0       │\n","│ 50%        ┆ null      ┆ null    ┆ 1343.0    ┆ … ┆ 46.0      ┆ 544.72    ┆ 76.46     ┆ 9.0       │\n","│ 75%        ┆ null      ┆ null    ┆ 2957.0    ┆ … ┆ 149.0     ┆ 611.59    ┆ 81.84     ┆ 20.0      │\n","│ max        ┆ supplierh ┆ 2024-06 ┆ 8019.0    ┆ … ┆ 210.0     ┆ 1969.0    ┆ 96.87     ┆ 43.0      │\n","└────────────┴───────────┴─────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"]},"execution_count":209,"metadata":{},"output_type":"execute_result"}],"source":["df_supplier_scorecard.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBaeS3Rbh8Pm","outputId":"5a385d93-2bf7-4e7d-caff-d80e9698dfc3"},"outputs":[{"data":{"text/plain":["Schema([('SupplierName', String),\n","        ('Month', String),\n","        ('PackagesHandled', Int64),\n","        ('BadPackagingRate (%)', Float64),\n","        ('TotalIncidents', Int64),\n","        ('AverageCostPerIncident (€)', Float64),\n","        ('OnTimeDeliveryRate (%)', Float64),\n","        ('AnomaliesDetected', Int64)])"]},"execution_count":210,"metadata":{},"output_type":"execute_result"}],"source":["#now we will see the structure of the file\n","df_supplier_scorecard.schema"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EGePsKgoh8Pm","outputId":"1f0679bf-8a1a-4bd0-f655-26c0ee591277"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of duplicate rows found: 0\n","Number of null values found: shape: (1, 8)\n","┌────────────┬───────┬────────────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n","│ SupplierNa ┆ Month ┆ PackagesHa ┆ BadPackagi ┆ TotalIncid ┆ AverageCos ┆ OnTimeDeli ┆ AnomaliesD │\n","│ me         ┆ ---   ┆ ndled      ┆ ngRate (%) ┆ ents       ┆ tPerIncide ┆ veryRate   ┆ etected    │\n","│ ---        ┆ u32   ┆ ---        ┆ ---        ┆ ---        ┆ nt (€)     ┆ (%)        ┆ ---        │\n","│ u32        ┆       ┆ u32        ┆ u32        ┆ u32        ┆ ---        ┆ ---        ┆ u32        │\n","│            ┆       ┆            ┆            ┆            ┆ u32        ┆ u32        ┆            │\n","╞════════════╪═══════╪════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n","│ 0          ┆ 0     ┆ 0          ┆ 0          ┆ 0          ┆ 0          ┆ 0          ┆ 0          │\n","└────────────┴───────┴────────────┴────────────┴────────────┴────────────┴────────────┴────────────┘\n"]}],"source":["# do we have duplicate rows\n","num_duplicates = df_supplier_scorecard.is_duplicated().sum()\n","print(f\"Number of duplicate rows found: {num_duplicates}\")\n","# do we have null values?\n","num_nulls = df_supplier_scorecard.null_count()\n","print(f\"Number of null values found: {num_nulls}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Ysp2iGih8Pm","outputId":"3649a3c5-4e77-489a-f45d-b844996f53ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Viewing rows where (SupplierName, Month) combinations are duplicated (showing first ~10 duplicates):\n","shape: (0, 8)\n","┌────────────┬───────┬────────────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n","│ SupplierNa ┆ Month ┆ PackagesHa ┆ BadPackagi ┆ TotalIncid ┆ AverageCos ┆ OnTimeDeli ┆ AnomaliesD │\n","│ me         ┆ ---   ┆ ndled      ┆ ngRate (%) ┆ ents       ┆ tPerIncide ┆ veryRate   ┆ etected    │\n","│ ---        ┆ str   ┆ ---        ┆ ---        ┆ ---        ┆ nt (€)     ┆ (%)        ┆ ---        │\n","│ str        ┆       ┆ i64        ┆ f64        ┆ i64        ┆ ---        ┆ ---        ┆ i64        │\n","│            ┆       ┆            ┆            ┆            ┆ f64        ┆ f64        ┆            │\n","╞════════════╪═══════╪════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n","└────────────┴───────┴────────────┴────────────┴────────────┴────────────┴────────────┴────────────┘\n"]}],"source":["\n","# Identify the combinations that are duplicated\n","duplicated_keys = (\n","    df_supplier_scorecard\n","    .group_by(['SupplierName', 'Month'])\n","    .agg(pl.len().alias('count'))\n","    .filter(pl.col('count') > 1)\n","    .select(['SupplierName', 'Month']) # Select only the key columns\n",")\n","\n","# Join back to the original data to get ALL columns for the duplicated keys\n","# Use an inner join to only get rows matching the duplicated keys\n","view_duplicates = duplicated_keys.join(\n","    df_supplier_scorecard,\n","    on=['SupplierName', 'Month'],\n","    how='inner'\n",").sort(['SupplierName', 'Month']) # Sort to see duplicates grouped together\n","\n","print(f\"Viewing rows where (SupplierName, Month) combinations are duplicated (showing first ~10 duplicates):\")\n","\n","# Show enough rows to see a few examples of duplicates\n","print(view_duplicates.head(10))\n","\n","# You might want to look at a specific example found earlier, e.g., SupplierA / 2023-02-01\n","# print(\"\\nExample: SupplierA for 2023-02-01\")\n","# print(df_supplier_scorecard.filter(\n","#     (pl.col('SupplierName') == 'SupplierA') & (pl.col('Month') == pl.lit(date(2023, 2, 1))) # Need lit() and date object if comparing directly\n","# ))"]},{"cell_type":"markdown","metadata":{"id":"X_rVSxIth8Pn"},"source":["### Time of day"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLalvyZMh8Pn","outputId":"79a39561-6abd-4715-ebf4-737b4b0aa583"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dtype of Month: String\n","New dtype of Month: Date\n","Successfully converted Month column to Date type.\n","\n","Sample data after Month conversion:\n","shape: (3, 8)\n","┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n","│ SupplierNa ┆ Month      ┆ PackagesHa ┆ BadPackag ┆ TotalInci ┆ AverageCo ┆ OnTimeDel ┆ Anomalies │\n","│ me         ┆ ---        ┆ ndled      ┆ ingRate   ┆ dents     ┆ stPerInci ┆ iveryRate ┆ Detected  │\n","│ ---        ┆ date       ┆ ---        ┆ (%)       ┆ ---       ┆ dent (€)  ┆ (%)       ┆ ---       │\n","│ str        ┆            ┆ i64        ┆ ---       ┆ i64       ┆ ---       ┆ ---       ┆ i64       │\n","│            ┆            ┆            ┆ f64       ┆           ┆ f64       ┆ f64       ┆           │\n","╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n","│ SupplierA  ┆ 2023-01-01 ┆ 7841       ┆ 8.46      ┆ 133       ┆ 538.23    ┆ 86.01     ┆ 23        │\n","│ SupplierA  ┆ 2023-02-01 ┆ 7196       ┆ 7.78      ┆ 153       ┆ 572.14    ┆ 88.09     ┆ 16        │\n","│ SupplierA  ┆ 2023-03-01 ┆ 7842       ┆ 7.94      ┆ 163       ┆ 547.51    ┆ 84.74     ┆ 21        │\n","└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘\n"]}],"source":["print(f\"Original dtype of Month: {df_supplier_scorecard['Month'].dtype}\")\n","\n","try:\n","    # Convert 'YYYY-MM' string to Date (defaults to 1st of the month)\n","    df_supplier_scorecard = df_supplier_scorecard.with_columns(\n","        pl.col(\"Month\").str.to_date(\"%Y-%m\").alias(\"Month\")\n","    )\n","    # Verify the change\n","    print(f\"New dtype of Month: {df_supplier_scorecard['Month'].dtype}\")\n","    print(\"Successfully converted Month column to Date type.\")\n","    print(\"\\nSample data after Month conversion:\")\n","    print(df_supplier_scorecard.head(3))\n","\n","except Exception as e:\n","    print(f\"Error converting Month column: {e}\")\n","    print(\"Please check if all values strictly follow the 'YYYY-MM' format.\")"]},{"cell_type":"markdown","metadata":{"id":"2zYGyGqZh8Pn"},"source":["### Naming consistency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpisuYfTh8Pn","outputId":"a71885f3-2277-48c4-9b6c-4b2d3eb554b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking Unique Values for Potential Inconsistencies in Historical Incidents\n","Unique values in: SupplierName\n","['SPLF', 'SuplA', 'SupllierC', 'SuppB', 'SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH', 'supplierA', 'supplierh']\n","Total unique non-null values: 14\n"]}],"source":["columns_to_check = [\n","    'SupplierName']\n","\n","print(\"Checking Unique Values for Potential Inconsistencies in Historical Incidents\")\n","\n","for col_name in columns_to_check:\n","    if col_name in df_supplier_scorecard.columns:\n","        try:\n","            unique_values = (\n","                df_supplier_scorecard[col_name]\n","                .unique()\n","                .sort()\n","            )\n","\n","            print(f\"Unique values in: {col_name}\")\n","            print(unique_values.to_list())\n","            print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")\n","\n","        except Exception as e:\n","            print(f\"Could not process column: {col_name}\")\n","            print(f\"Error: {e}\")\n","    else:\n","        print(f\"Column not found: {col_name}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OlYzK3nQh8Po","outputId":"041ac40c-9ec7-4414-a253-5870220bba83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values in: SupplierName\n","['SupplierA', 'SupplierB', 'SupplierC', 'SupplierD', 'SupplierE', 'SupplierF', 'SupplierG', 'SupplierH']\n","Total unique non-null values: 8\n"]}],"source":["#fixing SupplierName\n","supplier_mapping_ss = {\n","    'SuplA': 'SupplierA',\n","    'supplierA': 'SupplierA',\n","    'SuppB': 'SupplierB',\n","    'SupllierC': 'SupplierC',\n","    'SPLF': 'SupplierF',\n","    'supplierh': 'SupplierH',\n","}\n","\n","# Apply the mapping\n","df_supplier_scorecard = df_supplier_scorecard.with_columns(\n","    pl.col('SupplierName')\n","      .str.strip_chars()\n","      .replace(supplier_mapping_ss)\n","      .str.replace_all(\" \", \"\")\n","      .alias('SupplierName')\n",")\n","\n","# Check the unique values again\n","unique_values = (\n","    df_supplier_scorecard['SupplierName']\n","    .unique()\n","    .sort()\n",")\n","print(f\"Unique values in: SupplierName\")\n","print(unique_values.to_list())\n","print(f\"Total unique non-null values: {len(unique_values.drop_nulls())}\")"]},{"cell_type":"markdown","metadata":{"id":"8F-6S26Lh8Pp"},"source":["### Data Duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvJX5Wz3h8Pp","outputId":"42d2e8ff-f6e4-41b8-ea53-bc990671e7bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Viewing rows where (SupplierName, Month) combinations are duplicated (showing first ~10 duplicates):\n","shape: (10, 8)\n","┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n","│ SupplierNa ┆ Month      ┆ PackagesHa ┆ BadPackag ┆ TotalInci ┆ AverageCo ┆ OnTimeDel ┆ Anomalies │\n","│ me         ┆ ---        ┆ ndled      ┆ ingRate   ┆ dents     ┆ stPerInci ┆ iveryRate ┆ Detected  │\n","│ ---        ┆ date       ┆ ---        ┆ (%)       ┆ ---       ┆ dent (€)  ┆ (%)       ┆ ---       │\n","│ str        ┆            ┆ i64        ┆ ---       ┆ i64       ┆ ---       ┆ ---       ┆ i64       │\n","│            ┆            ┆            ┆ f64       ┆           ┆ f64       ┆ f64       ┆           │\n","╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n","│ SupplierA  ┆ 2023-01-01 ┆ 102        ┆ 19.61     ┆ 1         ┆ 261.0     ┆ 74.56     ┆ 0         │\n","│ SupplierA  ┆ 2023-01-01 ┆ 76         ┆ 14.47     ┆ 3         ┆ 591.0     ┆ 87.86     ┆ 2         │\n","│ SupplierA  ┆ 2023-01-01 ┆ 7841       ┆ 8.46      ┆ 133       ┆ 538.23    ┆ 86.01     ┆ 23        │\n","│ SupplierA  ┆ 2023-02-01 ┆ 7196       ┆ 7.78      ┆ 153       ┆ 572.14    ┆ 88.09     ┆ 16        │\n","│ SupplierA  ┆ 2023-02-01 ┆ 85         ┆ 14.12     ┆ 6         ┆ 427.67    ┆ 88.06     ┆ 1         │\n","│ SupplierA  ┆ 2023-02-01 ┆ 75         ┆ 24.0      ┆ 1         ┆ 438.0     ┆ 76.49     ┆ 1         │\n","│ SupplierA  ┆ 2023-03-01 ┆ 7842       ┆ 7.94      ┆ 163       ┆ 547.51    ┆ 84.74     ┆ 21        │\n","│ SupplierA  ┆ 2023-03-01 ┆ 103        ┆ 16.5      ┆ 5         ┆ 714.4     ┆ 86.72     ┆ 0         │\n","│ SupplierA  ┆ 2023-03-01 ┆ 100        ┆ 20.0      ┆ 2         ┆ 250.5     ┆ 83.55     ┆ 1         │\n","│ SupplierA  ┆ 2023-04-01 ┆ 89         ┆ 20.22     ┆ 3         ┆ 642.42    ┆ 78.75     ┆ 1         │\n","└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘\n"]}],"source":["\n","# Identify the combinations that are duplicated\n","duplicated_keys = (\n","    df_supplier_scorecard\n","    .group_by(['SupplierName', 'Month'])\n","    .agg(pl.len().alias('count'))\n","    .filter(pl.col('count') > 1)\n","    .select(['SupplierName', 'Month']) # Select only the key columns\n",")\n","\n","# Join back to the original data to get ALL columns for the duplicated keys\n","# Use an inner join to only get rows matching the duplicated keys\n","view_duplicates = duplicated_keys.join(\n","    df_supplier_scorecard,\n","    on=['SupplierName', 'Month'],\n","    how='inner'\n",").sort(['SupplierName', 'Month']) # Sort to see duplicates grouped together\n","\n","print(f\"Viewing rows where (SupplierName, Month) combinations are duplicated (showing first ~10 duplicates):\")\n","\n","# Show enough rows to see a few examples of duplicates\n","print(view_duplicates.head(10))\n"]},{"cell_type":"markdown","metadata":{"id":"-6E6RwcJh8Pp"},"source":["## Export"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnJWbLRWX6x-"},"outputs":[],"source":["df_density_report.write_csv(EXPORT_DENSITY_REPORT, separator=\";\")\n","df_historical_incidents.write_csv(EXPORT_HISTORICAL_INCIDENTS, separator=\";\")\n","df_product_attributes.write_csv(EXPORT_PRODUCT_ATTRIBUTES, separator=\";\")\n","df_supplier_scorecard.write_csv(EXPORT_SUPPLIER_SCORECARD, separator=\";\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}