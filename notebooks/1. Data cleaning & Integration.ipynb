{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_9nryk7DPtX"
   },
   "source": [
    "# Data cleaning & Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBARle-BiX4b"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13742,
     "status": "ok",
     "timestamp": 1747002606098,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "UDa2w5NgiZKW",
    "outputId": "9f21586f-56ca-4475-eff0-4aa7632b14a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastexcel in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (from fastexcel) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (from pyarrow>=8.0.0->fastexcel) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4845,
     "status": "ok",
     "timestamp": 1747005925514,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "bPoCO-5gqsqE",
    "outputId": "d5fd5238-358a-43de-9c5f-406b99c6ac07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in /Users/ulisesgordillo/anaconda3/lib/python3.11/site-packages (3.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-91n0nF9meD"
   },
   "source": [
    "Side note: It will be useful to put all the required libraries in a requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747008551284,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "Z_JWQ-EZFOd0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l751Y4pzFSGQ"
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1747009259481,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "2r_OfAHoFWCq"
   },
   "outputs": [],
   "source": [
    "# Input paths\n",
    "PATH_DENSITY_REPORT       = 'DensityReports.xlsx'\n",
    "PATH_HISTORICAL_INCIDENTS = 'HistoricalIncidents.xlsx'\n",
    "PATH_PRODUCT_ATTRIBUTES   = 'ProductAttributes.xlsx'\n",
    "PATH_SUPPLIER_SCORECARD   = 'SupplierScorecard.xlsx'\n",
    "\n",
    "# Export paths\n",
    "EXPORT_DENSITY_REPORT       = 'density_report.xlsx'\n",
    "EXPORT_HISTORICAL_INCIDENTS = 'historical_incidents.xlsx'\n",
    "EXPORT_PRODUCT_ATTRIBUTES   = 'product_attributes.xlsx'\n",
    "EXPORT_SUPPLIER_SCORECARD   = 'supplier_scorecard.xlsx'\n",
    "EXPORT_FULL_JOIN            = 'full_join.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZpkTTkwilQu"
   },
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKxU3mwf_4BN"
   },
   "source": [
    "### 1. Read excel files with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747002617176,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "zut0lQNJioXd"
   },
   "outputs": [],
   "source": [
    "def polars_read_excel(file_name, sheet_name='Sheet1'):\n",
    "  return pl.read_excel(source=file_name, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKHEnncl_-YM"
   },
   "source": [
    "### 2. Removing invalid strings in Product Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747002916743,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "trr2YqLyAbRk"
   },
   "outputs": [],
   "source": [
    "def clean_product_reference_column(df: pl.DataFrame, column_name: str, valid_pattern: str = r\"^PRD\\d{5}$\") -> pl.DataFrame:\n",
    "    # Ensure the column is cast to string\n",
    "    series_string = df[column_name].cast(pl.Utf8, strict=False)\n",
    "\n",
    "    # Remove trailing 'X' characters\n",
    "    cleaned_series = series_string.str.strip_chars_end('X')\n",
    "\n",
    "    # Check which values match the valid pattern\n",
    "    is_valid = cleaned_series.str.contains(valid_pattern)\n",
    "\n",
    "    # Replace invalid entries with None\n",
    "    corrected_series = pl.when(is_valid).then(cleaned_series).otherwise(None)\n",
    "\n",
    "    # Return the dataframe with the updated column\n",
    "    return df.with_columns([corrected_series.alias(column_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbmzxdzCUiR8"
   },
   "source": [
    "### 3. Modify column based on a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747003370199,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "HhAcOJM4Ug0s"
   },
   "outputs": [],
   "source": [
    "def clean_column_with_mapping(df: pl.DataFrame, col_name: str, mapping_dict: dict) -> pl.DataFrame:\n",
    "    cleaned_col = (\n",
    "        df[col_name]\n",
    "        .cast(pl.Utf8, strict=False)\n",
    "        .str.strip_chars()\n",
    "        .str.replace_all(\" \", \"\")\n",
    "        .map_elements(lambda val: mapping_dict.get(val, val), return_dtype=pl.Utf8)\n",
    "    )\n",
    "\n",
    "    return df.with_columns([cleaned_col.alias(col_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ_hUhl5x3pr"
   },
   "source": [
    "### 4. Most frequent combination of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747003796490,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "5HMa-ZVqx3Eg"
   },
   "outputs": [],
   "source": [
    "def most_common_combination(df: pl.DataFrame, group_cols: list[str], additional_cols: list[str] = []) -> pl.DataFrame:\n",
    "  return (\n",
    "      df\n",
    "      .group_by(group_cols + additional_cols)\n",
    "      .agg(pl.len().alias(\"count\"))\n",
    "      .sort(group_cols + [\"count\"], descending=[False] * len(group_cols) + [True])\n",
    "      .unique(subset=group_cols, keep='first')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpo3gFfBar6l"
   },
   "source": [
    "### 5. Replace invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1747003835279,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "uVZ-rF7rasTE"
   },
   "outputs": [],
   "source": [
    "def replace_invalid_values(df: pl.DataFrame, target_col: str, invalid_values: list[str], group_cols: list[str]) -> pl.DataFrame:\n",
    "\n",
    "    # Get most common valid values per group\n",
    "    df_most_common = most_common_combination(\n",
    "        df.filter(~pl.col(target_col).is_in(invalid_values)),\n",
    "        group_cols,\n",
    "        additional_cols=[target_col]\n",
    "    )\n",
    "\n",
    "    # Build replacements for each invalid value\n",
    "    fixed_parts = []\n",
    "    for val in invalid_values:\n",
    "        df_invalid = df.filter(pl.col(target_col) == val)\n",
    "        df_replaced = (\n",
    "            df_invalid.drop(target_col)\n",
    "            .join(\n",
    "                df_most_common.select(group_cols + [target_col]),\n",
    "                on=group_cols,\n",
    "                how=\"left\"\n",
    "            )\n",
    "        )\n",
    "        fixed_parts.append(df_replaced)\n",
    "\n",
    "    # Retain all valid entries\n",
    "    df_cleaned = df.filter(~pl.col(target_col).is_in(invalid_values))\n",
    "\n",
    "    # Ensure consistent column order\n",
    "    column_order = df_cleaned.columns\n",
    "    fixed_parts = [part.select(column_order) for part in fixed_parts]\n",
    "\n",
    "    return pl.concat([df_cleaned] + fixed_parts, how=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQmXcW2oaEwG"
   },
   "source": [
    "### 6. Supplier Scorecard aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1747005237667,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "bKUKsTMdaEwH"
   },
   "outputs": [],
   "source": [
    "def aggregate_supplier_scorecard(df_scorecard: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Aggregate core metrics\n",
    "    df_agg = df_scorecard.group_by(['SupplierName', 'Month']).agg([\n",
    "        pl.sum('PackagesHandled').alias('PackagesHandled'),\n",
    "        pl.sum('TotalIncidents').alias('TotalIncidents'),\n",
    "        pl.sum('AnomaliesDetected').alias('AnomaliesDetected'),\n",
    "        (pl.col('PackagesHandled') * pl.col('BadPackagingRate (%)') / 100).sum().alias('TotalBadPackages'),\n",
    "        (pl.col('PackagesHandled') * pl.col('OnTimeDeliveryRate (%)') / 100).sum().alias('TotalOnTimePackages'),\n",
    "        (pl.col('AverageCostPerIncident (€)') * pl.col('TotalIncidents')).sum().alias('TotalIncidentCost')\n",
    "    ])\n",
    "\n",
    "    # Calculate final KPIs and round\n",
    "    ph = pl.col('PackagesHandled')\n",
    "    ti = pl.col('TotalIncidents')\n",
    "\n",
    "    df_final = df_agg.with_columns([\n",
    "        (pl.when(ph > 0).then(pl.col('TotalBadPackages') * 100 / ph).otherwise(0.0))\n",
    "        .round(2).alias('BadPackagingRate (%)'),\n",
    "\n",
    "        (pl.when(ph > 0).then(pl.col('TotalOnTimePackages') * 100 / ph).otherwise(None))\n",
    "        .round(2).alias('OnTimeDeliveryRate (%)'),\n",
    "\n",
    "        (pl.when(ti > 0).then(pl.col('TotalIncidentCost') / ti).otherwise(0.0))\n",
    "        .round(2).alias('AverageCostPerIncident (€)')\n",
    "    ]).drop([\n",
    "        'TotalBadPackages',\n",
    "        'TotalOnTimePackages',\n",
    "        'TotalIncidentCost'\n",
    "    ])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz7f_w9i7yOS"
   },
   "source": [
    "## File reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 9296,
     "status": "ok",
     "timestamp": 1747004633533,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "JHwC_pv27jgP"
   },
   "outputs": [],
   "source": [
    "df_density_report       = polars_read_excel(PATH_DENSITY_REPORT)\n",
    "df_historical_incidents = polars_read_excel(PATH_HISTORICAL_INCIDENTS)\n",
    "df_product_attributes   = polars_read_excel(PATH_PRODUCT_ATTRIBUTES)\n",
    "df_supplier_scorecard   = polars_read_excel(PATH_SUPPLIER_SCORECARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sngLbxheFs0s"
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h23cwY4AFwlb"
   },
   "source": [
    "### 1. Density Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkjOR4F57jgQ"
   },
   "source": [
    "#### 1.1 Product Reference correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747004636513,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "gw3-Gu1z-Ta3"
   },
   "outputs": [],
   "source": [
    "df_density_report = clean_product_reference_column(df_density_report, \"ProductReference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4fKCXnSh8N-"
   },
   "source": [
    "#### 1.2 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1747004640803,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yItquxA2RxXf"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "method_mapping = {\n",
    "    'Methd1': 'Method1',\n",
    "    'Method_2': 'Method2',\n",
    "}\n",
    "\n",
    "layout_mapping = {\n",
    "    'layouta': 'LayoutA',\n",
    "    'LayC': 'LayoutC',\n",
    "}\n",
    "\n",
    "quality_mapping = {\n",
    "    'GOOD': 'Good',\n",
    "    'bad': 'Bad',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'SupplierName', supplier_mapping)\n",
    "\n",
    "# Apply method, layout, and quality mappings\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'ProposedFoldingMethod', method_mapping)\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'ProposedLayout', layout_mapping)\n",
    "df_density_report = clean_column_with_mapping(df_density_report, 'PackagingQuality', quality_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDL2cZxXtgBB"
   },
   "source": [
    "#### 1.3 Incorrect input labels modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3374,
     "status": "ok",
     "timestamp": 1747004644180,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "yELE07S4agFR"
   },
   "outputs": [],
   "source": [
    "# Define grouping columns\n",
    "group_cols_for_folding = [\n",
    "    \"SupplierName\",\n",
    "    \"GarmentType\",\n",
    "    \"Material\",\n",
    "    \"Weight\",\n",
    "    \"ProposedUnitsPerCarton\",\n",
    "    \"ProposedLayout\",\n",
    "    \"PackagingQuality\"\n",
    "]\n",
    "\n",
    "group_cols_for_layout = [\n",
    "    \"SupplierName\",\n",
    "    \"GarmentType\",\n",
    "    \"Material\",\n",
    "    \"Weight\",\n",
    "    \"ProposedUnitsPerCarton\",\n",
    "    \"ProposedFoldingMethod\",\n",
    "    \"PackagingQuality\"\n",
    "]\n",
    "\n",
    "# Replace invalid values in ProposedFoldingMethod\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedFoldingMethod\",\n",
    "    invalid_values=[\"FoldX\", \"None\"],\n",
    "    group_cols=group_cols_for_folding\n",
    ")\n",
    "\n",
    "# Replace invalid values in ProposedLayout\n",
    "df_density_report = replace_invalid_values(\n",
    "    df_density_report,\n",
    "    target_col=\"ProposedLayout\",\n",
    "    invalid_values=[\"Box9\", \"LayoutX\"],\n",
    "    group_cols=group_cols_for_layout\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X9-o6dzaEwL"
   },
   "source": [
    "#### 1.4 Drop incorrect values of number of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1747006407789,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "d5jd38jmaEwL"
   },
   "outputs": [],
   "source": [
    "# Clean ProposedUnitsPerCarton: set invalid values to null\n",
    "df_density_report = df_density_report.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") <= 0) |\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") % 1 != 0) |\n",
    "        (pl.col(\"ProposedUnitsPerCarton\") > 100)\n",
    "    )\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"ProposedUnitsPerCarton\"))\n",
    "    .alias(\"ProposedUnitsPerCarton\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjEfI6mnUI5_"
   },
   "source": [
    "### 2. Historical Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7rEeXM3lOYE"
   },
   "source": [
    "#### 2.1 Product Reference correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747004645743,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "ENUv-HL_lQpG"
   },
   "outputs": [],
   "source": [
    "df_historical_incidents = clean_product_reference_column(df_historical_incidents, \"ProductReference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nofHuxBblkaz"
   },
   "source": [
    "#### 2.2 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747004647422,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "jhg7isrHllex"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_historical_incidents = clean_column_with_mapping(df_historical_incidents, 'SupplierName', supplier_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4vmAYqoVHzI"
   },
   "source": [
    "### 3. Product Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBaiu_s6Wk7w"
   },
   "source": [
    "No further cleaning of this dataset is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNl3APC6WmW9"
   },
   "source": [
    "### 4. Supplier Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OBohECZmjiL"
   },
   "source": [
    "#### 4.1 Naming consistency generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747004927891,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "DR9Dx3r_mifw"
   },
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "supplier_mapping = {\n",
    "    'SuplA':     'SupplierA',\n",
    "    'supplierA': 'SupplierA',\n",
    "    'SuppB':     'SupplierB',\n",
    "    'SupllierC': 'SupplierC',\n",
    "    'SPLF':      'SupplierF',\n",
    "    'supplierh': 'SupplierH',\n",
    "}\n",
    "\n",
    "# Apply supplier mapping\n",
    "df_supplier_scorecard = clean_column_with_mapping(df_supplier_scorecard, 'SupplierName', supplier_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdtzQZ0bo13R"
   },
   "source": [
    "#### 4.2 Grouping correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747005444879,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "i4xyawX2o0b6"
   },
   "outputs": [],
   "source": [
    "df_supplier_scorecard_agg = aggregate_supplier_scorecard(df_supplier_scorecard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6E6RwcJh8Pp"
   },
   "source": [
    "### 5. Export separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70527,
     "status": "ok",
     "timestamp": 1747006005002,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "8D7V4kjbqNjm",
    "outputId": "f4507732-f918-41f8-8416-906b5010e32d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x32a19c690>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_density_report.write_excel(EXPORT_DENSITY_REPORT)\n",
    "df_historical_incidents.write_excel(EXPORT_HISTORICAL_INCIDENTS)\n",
    "df_product_attributes.write_excel(EXPORT_PRODUCT_ATTRIBUTES)\n",
    "df_supplier_scorecard.write_excel(EXPORT_SUPPLIER_SCORECARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU0WR4BQrvBm"
   },
   "source": [
    "## Dataframe integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtkTkq3UvDYO"
   },
   "source": [
    "### 1. Nulls filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747007698444,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "hvgpXvDIrxGn"
   },
   "outputs": [],
   "source": [
    "df_density_report_join = df_density_report.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null() &\n",
    "    pl.col(\"ProposedUnitsPerCarton\").is_not_null() &\n",
    "    pl.col(\"ProposedFoldingMethod\").is_not_null() &\n",
    "    pl.col(\"ProposedLayout\").is_not_null()\n",
    ")\n",
    "\n",
    "df_historical_incidents_join = df_historical_incidents.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null()\n",
    ")\n",
    "\n",
    "df_product_attributes_join = df_product_attributes.filter(\n",
    "    pl.col(\"ProductReference\").is_not_null()\n",
    ")\n",
    "\n",
    "df_supplier_scorecard_join = df_supplier_scorecard_agg.filter(\n",
    "    pl.col(\"SupplierName\").is_not_null()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EydBEf9mviUs"
   },
   "source": [
    "### 2. Dataframes joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1747007826472,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "19D0LYivvhMv"
   },
   "outputs": [],
   "source": [
    "df_full_join = df_density_report_join.join(\n",
    "    df_product_attributes_join.select([\"ProductReference\", \"Size\", \"Collection\"]),\n",
    "    on=\"ProductReference\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# We create a new column to join with the scorecard dataframe\n",
    "df_full_join = df_full_join.with_columns(\n",
    "    pl.col(\"DateOfReport\").map_elements(\n",
    "        lambda d: (d - relativedelta(months=1)).strftime(\"%Y-%m\"),\n",
    "        return_dtype=pl.Utf8\n",
    "    ).alias(\"PreviousMonth\")\n",
    ")\n",
    "\n",
    "df_full_join = df_full_join.join(\n",
    "    df_supplier_scorecard_join,\n",
    "    left_on=[\"SupplierName\", \"PreviousMonth\"],\n",
    "    right_on=[\"SupplierName\", \"Month\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/z6pvq_495gd075z979mzth4r0000gn/T/ipykernel_14022/5699636.py:9: DeprecationWarning: `DataFrame.with_row_count` is deprecated. Use `with_row_index` instead. Note that the default column name has changed from 'row_nr' to 'index'.\n",
      "  df_incidents_with_id = df_incidents_with_id.with_row_count(name=INCIDENT_ID_COL)\n"
     ]
    }
   ],
   "source": [
    "#  Configuration \n",
    "INCIDENT_ID_COL = \"IncidentID_AutoGen\"\n",
    "JOIN_KEYS_DENSITY_INCIDENTS = [\"ProductReference\", \"SupplierName\"]\n",
    "TIME_WINDOW_DAYS = 14\n",
    "\n",
    "# 1. Ensure unique ID for original incidents\n",
    "df_incidents_with_id = df_historical_incidents.clone()\n",
    "if INCIDENT_ID_COL not in df_incidents_with_id.columns:\n",
    "    df_incidents_with_id = df_incidents_with_id.with_row_count(name=INCIDENT_ID_COL)\n",
    "elif not df_incidents_with_id.get_column(INCIDENT_ID_COL).is_unique().all():\n",
    "    df_incidents_with_id = df_incidents_with_id.drop(INCIDENT_ID_COL).with_row_count(name=INCIDENT_ID_COL)\n",
    "\n",
    "# 2. Create candidate matches\n",
    "df_candidates = df_density_report_join.join(\n",
    "    df_incidents_with_id,\n",
    "    on=JOIN_KEYS_DENSITY_INCIDENTS,\n",
    "    how=\"inner\"\n",
    ").filter(\n",
    "    (pl.col(\"DateOfIncident\") >= pl.col(\"DateOfReport\")) &\n",
    "    (pl.col(\"DateOfIncident\") <= pl.col(\"DateOfReport\") + pl.duration(days=TIME_WINDOW_DAYS))\n",
    ")\n",
    "\n",
    "# 3. MODIFIED De-duplication: Each incident links to at most ONE ReportID (its \"best\" match)\n",
    "df_report_to_incident_link = pl.DataFrame() # Initialize empty\n",
    "if df_candidates.height > 0:\n",
    "    df_candidates_with_lag = df_candidates.with_columns(\n",
    "        (pl.col(\"DateOfIncident\") - pl.col(\"DateOfReport\")).dt.total_days().alias(\"days_lag\")\n",
    "    )\n",
    "    df_sorted_candidates_for_incident = df_candidates_with_lag.sort(\n",
    "        INCIDENT_ID_COL, \"days_lag\", \"DateOfReport\", \"ReportID\" # Sort order defines \"best\"\n",
    "    )\n",
    "    df_report_to_incident_link = df_sorted_candidates_for_incident.group_by(\n",
    "        INCIDENT_ID_COL, maintain_order=True\n",
    "    ).first()\n",
    "else: # Handle case where df_candidates is empty\n",
    "    empty_schema_df_for_link = df_density_report_join.head(0).join(\n",
    "            df_incidents_with_id.head(0), on=JOIN_KEYS_DENSITY_INCIDENTS, how=\"inner\"\n",
    "        ).with_columns(pl.lit(None, dtype=pl.Int64).alias(\"days_lag\"))\n",
    "    df_report_to_incident_link = empty_schema_df_for_link.clear()\n",
    "\n",
    "\n",
    "# 4. Integration\n",
    "incident_details_to_add = [\n",
    "    INCIDENT_ID_COL, \"DateOfIncident\", \"CostImpact (€)\", \"IssueDescription\", \"ResolutionStatus\"\n",
    "]\n",
    "cols_from_link_to_select = [\"ReportID\"] + [\n",
    "    col for col in incident_details_to_add if col in df_report_to_incident_link.columns\n",
    "]\n",
    "\n",
    "df_full_join = df_full_join.join(\n",
    "    df_report_to_incident_link.select(cols_from_link_to_select),\n",
    "    on=\"ReportID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nays8JT93MEg"
   },
   "source": [
    "### 3. Dataframes joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128925,
     "status": "ok",
     "timestamp": 1747009392612,
     "user": {
      "displayName": "Francisco",
      "userId": "11190877053062531761"
     },
     "user_tz": 300
    },
    "id": "c3XHEhpT3RyX",
    "outputId": "e54e3e0c-a44c-40fd-dcf3-5a262775840f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x32a1dd450>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_join.write_excel(EXPORT_FULL_JOIN)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nBARle-BiX4b",
    "l751Y4pzFSGQ",
    "tKxU3mwf_4BN",
    "uKHEnncl_-YM",
    "kbmzxdzCUiR8",
    "WZ_hUhl5x3pr",
    "Zpo3gFfBar6l",
    "e5zgJF_NaEwB",
    "YQmXcW2oaEwG",
    "kz7f_w9i7yOS",
    "wkjOR4F57jgQ",
    "E4fKCXnSh8N-",
    "bDL2cZxXtgBB",
    "6X9-o6dzaEwL",
    "Z7rEeXM3lOYE",
    "nofHuxBblkaz",
    "8OBohECZmjiL",
    "KdtzQZ0bo13R",
    "GtkTkq3UvDYO",
    "EydBEf9mviUs",
    "nays8JT93MEg"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
